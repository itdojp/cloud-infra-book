---
title: "ç¬¬10ç« ï¼šInfrastructure as Code (IaC) ã¨è‡ªå‹•åŒ–"
chapter: chapter10
layout: book
---

# ç¬¬10ç« ï¼šInfrastructure as Code (IaC) ã¨è‡ªå‹•åŒ–

## 10.1 IaCã®æ¦‚å¿µã¨ãƒ¡ãƒªãƒƒãƒˆ

### Infrastructure as Codeã¨ã„ã†æ€æƒ³ã®é©æ–°æ€§

Infrastructure as Codeï¼ˆIaCï¼‰ã¯ã€ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ç®¡ç†ã«ãŠã‘ã‚‹æœ€ã‚‚é‡è¦ãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆã®ä¸€ã¤ã§ã™ã€‚æ‰‹å‹•ã§ã‚µãƒ¼ãƒãƒ¼ã‚’è¨­å®šã—ã€GUIã§ã‚¯ãƒªãƒƒã‚¯ã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ãŸæ™‚ä»£ã‹ã‚‰ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ–ãƒ«ã§å†ç¾å¯èƒ½ãªæ–¹æ³•ã¸ã®ç§»è¡Œã¯ã€å˜ãªã‚‹åŠ¹ç‡åŒ–ã‚’è¶…ãˆã¦ã€ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®å“è³ªã€ä¿¡é ¼æ€§ã€ãã—ã¦é–‹ç™ºé€Ÿåº¦ã‚’æ ¹æœ¬çš„ã«å‘ä¸Šã•ã›ã¾ã—ãŸã€‚

### å®£è¨€çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨å‘½ä»¤çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æœ¬è³ª

IaCãƒ„ãƒ¼ãƒ«ã‚’ç†è§£ã™ã‚‹ä¸Šã§æœ€ã‚‚é‡è¦ãªæ¦‚å¿µã¯ã€å®£è¨€çš„ï¼ˆDeclarativeï¼‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨å‘½ä»¤çš„ï¼ˆImperativeï¼‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é•ã„ã§ã™ã€‚

**å®£è¨€çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šæœ›ã¾ã—ã„çŠ¶æ…‹ã®è¨˜è¿°**

å®£è¨€çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ã€Œã©ã®ã‚ˆã†ãªçŠ¶æ…‹ã§ã‚ã‚‹ã¹ãã‹ã€ã‚’è¨˜è¿°ã—ã¾ã™ã€‚

```hcl
# Terraform - å®£è¨€çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ä¾‹
resource "aws_instance" "web_servers" {
  count         = 3  # 3å°ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒå­˜åœ¨ã™ã¹ã
  instance_type = "t3.medium"
  ami           = data.aws_ami.amazon_linux_2.id
  
  subnet_id              = aws_subnet.public[count.index % length(aws_subnet.public)].id
  vpc_security_group_ids = [aws_security_group.web.id]
  
  tags = {
    Name        = "web-server-${count.index + 1}"
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
  
  # ç¾åœ¨2å°ã—ã‹ãªã„å ´åˆã€Terraformã¯è‡ªå‹•çš„ã«1å°è¿½åŠ 
  # ç¾åœ¨4å°ã‚ã‚‹å ´åˆã€Terraformã¯è‡ªå‹•çš„ã«1å°å‰Šé™¤
  # è¨­å®šãŒç•°ãªã‚‹å ´åˆã€Terraformã¯å·®åˆ†ã‚’é©ç”¨
}
```

**å‘½ä»¤çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šæ‰‹é †ã®è¨˜è¿°**

å‘½ä»¤çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ã€Œä½•ã‚’ã™ã¹ãã‹ã€ã®æ‰‹é †ã‚’è¨˜è¿°ã—ã¾ã™ã€‚

```python
# Python/Boto3 - å‘½ä»¤çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ä¾‹
import boto3

ec2 = boto3.resource('ec2')

# ç¾åœ¨ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°ã‚’ç¢ºèª
current_instances = list(ec2.instances.filter(
    Filters=[
        {'Name': 'tag:Name', 'Values': ['web-server-*']},
        {'Name': 'instance-state-name', 'Values': ['running']}
    ]
))

desired_count = 3
current_count = len(current_instances)

# ä¸è¶³åˆ†ã‚’è¿½åŠ 
if current_count < desired_count:
    for i in range(current_count, desired_count):
        instance = ec2.create_instances(
            ImageId='ami-0123456789abcdef0',
            InstanceType='t3.medium',
            MinCount=1,
            MaxCount=1,
            SubnetId=get_next_subnet(),
            SecurityGroupIds=['sg-1234567890abcdef0'],
            TagSpecifications=[{
                'ResourceType': 'instance',
                'Tags': [
                    {'Key': 'Name', 'Value': f'web-server-{i+1}'},
                    {'Key': 'Environment', 'Value': environment},
                    {'Key': 'ManagedBy', 'Value': 'Python Script'}
                ]
            }]
        )[0]
        print(f"Created instance: {instance.id}")
# éå‰°åˆ†ã‚’å‰Šé™¤
elif current_count > desired_count:
    for instance in current_instances[desired_count:]:
        instance.terminate()
        print(f"Terminated instance: {instance.id}")
```

### IaCãŒã‚‚ãŸã‚‰ã™æœ¬è³ªçš„ä¾¡å€¤

**1. å†ªç­‰æ€§ï¼ˆIdempotencyï¼‰ã®ä¿è¨¼**

å†ªç­‰æ€§ã¨ã¯ã€åŒã˜æ“ä½œã‚’ä½•åº¦å®Ÿè¡Œã—ã¦ã‚‚åŒã˜çµæœãŒå¾—ã‚‰ã‚Œã‚‹æ€§è³ªã§ã™ã€‚å®£è¨€çš„IaCãƒ„ãƒ¼ãƒ«ã¯ã€ã“ã®å†ªç­‰æ€§ã‚’è‡ªå‹•çš„ã«ä¿è¨¼ã—ã¾ã™ã€‚

```yaml
# å†ªç­‰æ€§ã®å®Ÿä¾‹
åˆæœŸçŠ¶æ…‹: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹0å°
1å›ç›®å®Ÿè¡Œ: 3å°ä½œæˆ â†’ çµæœ: 3å°
2å›ç›®å®Ÿè¡Œ: å¤‰æ›´ãªã— â†’ çµæœ: 3å°ï¼ˆå¤‰ã‚ã‚‰ãšï¼‰
3å›ç›®å®Ÿè¡Œ: å¤‰æ›´ãªã— â†’ çµæœ: 3å°ï¼ˆå¤‰ã‚ã‚‰ãšï¼‰

# è¨­å®šå¤‰æ›´æ™‚
è¨­å®šå¤‰æ›´: instance_type ã‚’ t3.large ã«å¤‰æ›´
4å›ç›®å®Ÿè¡Œ: 3å°ã‚’æ›´æ–° â†’ çµæœ: 3å°ï¼ˆt3.largeï¼‰
```

**2. ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã«ã‚ˆã‚‹å¤‰æ›´è¿½è·¡**

ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’ã‚³ãƒ¼ãƒ‰ã¨ã—ã¦ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã§åŸ¹ã‚ã‚ŒãŸãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨ã§ãã¾ã™ã€‚

```bash
# Git ã§ã®ã‚¤ãƒ³ãƒ•ãƒ©å¤‰æ›´ç®¡ç†
git log --oneline terraform/
# å‡ºåŠ›ä¾‹ï¼š
# a5f3c21 feat: Add auto-scaling for web servers
# 82b9e44 fix: Correct security group ingress rules
# 3d7a891 refactor: Extract RDS configuration to module
# f2c6b55 chore: Update instance types for cost optimization

# ç‰¹å®šã®å¤‰æ›´ã®è©³ç´°ç¢ºèª
git show a5f3c21
# å¤‰æ›´å†…å®¹ã€ç†ç”±ã€å½±éŸ¿ç¯„å›²ãŒæ˜ç¢ºã«è¨˜éŒ²ã•ã‚Œã‚‹
```

**3. ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¿ƒé€²**

```yaml
# ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã®ã‚¤ãƒ³ãƒ•ãƒ©å¤‰æ›´ãƒ¬ãƒ“ãƒ¥ãƒ¼
ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹:
  1. å¤‰æ›´æ¡ˆã®ä½œæˆ:
     - ãƒ–ãƒ©ãƒ³ãƒã§å¤‰æ›´ã‚’å®Ÿè£…
     - terraform plan ã®çµæœã‚’ç¢ºèª
     
  2. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:
     - å¤‰æ›´ã®æ„å›³ã‚’èª¬æ˜
     - å½±éŸ¿ç¯„å›²ã‚’æ˜è¨˜
     - ã‚³ã‚¹ãƒˆå½±éŸ¿ã‚’è¨˜è¼‰
     
  3. ãƒ¬ãƒ“ãƒ¥ãƒ¼:
     - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
     - ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ç¢ºèª
     - ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®æ¤œè¨
     
  4. æ‰¿èªã¨é©ç”¨:
     - è¤‡æ•°äººã«ã‚ˆã‚‹æ‰¿èª
     - è‡ªå‹•ãƒ†ã‚¹ãƒˆã®é€šé
     - æœ¬ç•ªç’°å¢ƒã¸ã®é©ç”¨
```

### IaCã®æˆç†Ÿåº¦ãƒ¢ãƒ‡ãƒ«

çµ„ç¹”ã®IaCæ¡ç”¨ãƒ¬ãƒ™ãƒ«ã‚’è©•ä¾¡ã—ã€æ®µéšçš„ãªæ”¹å–„ã‚’å›³ã‚‹ãŸã‚ã®æŒ‡æ¨™ã§ã™ã€‚

```yaml
ãƒ¬ãƒ™ãƒ«1 - æ‰‹å‹•é‹ç”¨:
  ç‰¹å¾´:
    - GUI/CLIã§ã®æ‰‹å‹•è¨­å®š
    - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–ã•ã‚Œã¦ã„ãªã„
    - å†ç¾æ€§ãªã—
  ãƒªã‚¹ã‚¯:
    - ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ã‚¨ãƒ©ãƒ¼
    - ç’°å¢ƒé–“ã®ä¸æ•´åˆ
    - éšœå®³å¾©æ—§ã®é…å»¶

ãƒ¬ãƒ™ãƒ«2 - ã‚¹ã‚¯ãƒªãƒ—ãƒˆåŒ–:
  ç‰¹å¾´:
    - ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã®éƒ¨åˆ†è‡ªå‹•åŒ–
    - åŸºæœ¬çš„ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
    - é™å®šçš„ãªå†ç¾æ€§
  æ”¹å–„ç‚¹:
    - æ‰‹å‹•ä½œæ¥­ã®å‰Šæ¸›
    - åŸºæœ¬çš„ãªæ¨™æº–åŒ–

ãƒ¬ãƒ™ãƒ«3 - IaCãƒ„ãƒ¼ãƒ«å°å…¥:
  ç‰¹å¾´:
    - Terraform/CloudFormationä½¿ç”¨
    - ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿæ–½
    - ç’°å¢ƒåˆ¥ç®¡ç†
  åˆ©ç‚¹:
    - å®£è¨€çš„ç®¡ç†
    - çŠ¶æ…‹ç®¡ç†
    - ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º

ãƒ¬ãƒ™ãƒ«4 - å®Œå…¨è‡ªå‹•åŒ–:
  ç‰¹å¾´:
    - CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ
    - è‡ªå‹•ãƒ†ã‚¹ãƒˆå®Ÿè£…
    - Policy as Code
  æˆæœ:
    - ç¶™ç¶šçš„ãƒ‡ãƒªãƒãƒªãƒ¼
    - ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è‡ªå‹•åŒ–
    - ã‚»ãƒ«ãƒ•ã‚µãƒ¼ãƒ“ã‚¹åŒ–

ãƒ¬ãƒ™ãƒ«5 - GitOps:
  ç‰¹å¾´:
    - Git as Single Source of Truth
    - Pullå‹ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
    - ç¶™ç¶šçš„ãªåŒæœŸ
  æœ€çµ‚å½¢:
    - å®Œå…¨ãªç›£æŸ»è¨¼è·¡
    - è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
    - å®£è¨€çš„é‹ç”¨
```

### IaCã®ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å¯¾ç­–

**1. æ‰‹å‹•å¤‰æ›´ã¨ã®æ··åœ¨ï¼ˆConfiguration Driftï¼‰**

æœ€ã‚‚ä¸€èˆ¬çš„ã§å±é™ºãªã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€IaCã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚’æ‰‹å‹•ã§å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã™ã€‚

```hcl
# ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã¨é˜²æ­¢ç­–
# 1. å®šæœŸçš„ãªãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º
resource "null_resource" "drift_check" {
  provisioner "local-exec" {
    command = <<-EOT
      terraform plan -detailed-exitcode > /dev/null
      if [ $? -eq 2 ]; then
        echo "ALERT: Configuration drift detected!"
        # Slackã‚„ãƒ¡ãƒ¼ãƒ«ã§ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
      fi
    EOT
  }
  
  triggers = {
    # 1æ™‚é–“ã”ã¨ã«å®Ÿè¡Œ
    time = timestamp()
  }
}

# 2. AWS Config Rules ã«ã‚ˆã‚‹ç›£è¦–
resource "aws_config_config_rule" "terraform_managed" {
  name = "terraform-managed-resources"
  
  source {
    owner             = "AWS"
    source_identifier = "REQUIRED_TAGS"
  }
  
  input_parameters = jsonencode({
    tag1Key = "ManagedBy"
    tag1Value = "Terraform"
  })
  
  # ã‚¿ã‚°ãŒãªã„ï¼ˆæ‰‹å‹•ä½œæˆã•ã‚ŒãŸï¼‰ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¤œå‡º
}

# 3. IAMãƒãƒªã‚·ãƒ¼ã«ã‚ˆã‚‹æ‰‹å‹•å¤‰æ›´ã®é˜²æ­¢
data "aws_iam_policy_document" "prevent_manual_changes" {
  statement {
    effect = "Deny"
    actions = [
      "ec2:*",
      "rds:*",
      "s3:*"
    ]
    resources = ["*"]
    
    condition {
      test     = "StringNotEquals"
      variable = "aws:userid"
      values   = [data.aws_caller_identity.terraform.user_id]
    }
    
    # Terraformå®Ÿè¡Œãƒ¦ãƒ¼ã‚¶ãƒ¼ä»¥å¤–ã®å¤‰æ›´ã‚’æ‹’å¦
  }
}
```

**2. çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸é©åˆ‡ãªç®¡ç†**

Terraformã®çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€å®Ÿéš›ã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã¨ã‚³ãƒ¼ãƒ‰ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹é‡è¦ãªæƒ…å ±ã§ã™ã€‚

```hcl
# ãƒªãƒ¢ãƒ¼ãƒˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®é©åˆ‡ãªè¨­å®š
terraform {
  backend "s3" {
    # çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜å…ˆ
    bucket = "terraform-state-bucket"
    key    = "prod/infrastructure/terraform.tfstate"
    region = "ap-northeast-1"
    
    # æš—å·åŒ–
    encrypt = true
    kms_key_id = "arn:aws:kms:ap-northeast-1:123456789012:key/abcd1234"
    
    # çŠ¶æ…‹ãƒ­ãƒƒã‚¯
    dynamodb_table = "terraform-state-lock"
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆå±¥æ­´ä¿æŒï¼‰
    versioning = true
    
    # ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
    acl = "bucket-owner-full-control"
  }
}

# DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆçŠ¶æ…‹ãƒ­ãƒƒã‚¯ç”¨ï¼‰
resource "aws_dynamodb_table" "terraform_locks" {
  name         = "terraform-state-lock"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"
  
  attribute {
    name = "LockID"
    type = "S"
  }
  
  server_side_encryption {
    enabled = true
  }
  
  tags = {
    Name        = "Terraform State Lock Table"
    Environment = "shared"
  }
}
```

**3. ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªæ§‹æˆ**

ã™ã¹ã¦ã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’å˜ä¸€ã®å·¨å¤§ãªæ§‹æˆã§ç®¡ç†ã™ã‚‹ã¨ã€æ§˜ã€…ãªå•é¡ŒãŒç™ºç”Ÿã—ã¾ã™ã€‚

```hcl
# é©åˆ‡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å‰²
# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
terraform/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ networking/
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ compute/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ security/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ prod/
â”‚       â””â”€â”€ ...
â””â”€â”€ global/
    â”œâ”€â”€ iam/
    â””â”€â”€ route53/

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä½¿ç”¨ä¾‹
module "network" {
  source = "../../modules/networking"
  
  environment         = var.environment
  cidr_block         = var.vpc_cidr
  availability_zones = data.aws_availability_zones.available.names
  
  enable_nat_gateway = var.environment == "prod" ? true : false
  single_nat_gateway = var.environment != "prod" ? true : false
}

module "compute" {
  source = "../../modules/compute"
  
  environment    = var.environment
  subnet_ids     = module.network.private_subnet_ids
  instance_type  = var.instance_types[var.environment]
  instance_count = var.instance_counts[var.environment]
  
  depends_on = [module.network]
}
```

## 10.2 Terraformã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ•ãƒ©æ§‹ç¯‰ã®å®Ÿè·µ

### Terraformã®è¨­è¨ˆå“²å­¦ã¨å†…éƒ¨å‹•ä½œ

Terraformã¯ã€HashiCorpãŒé–‹ç™ºã—ãŸæœ€ã‚‚äººæ°—ã®ã‚ã‚‹IaCãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ãã®è¨­è¨ˆå“²å­¦ã‚’æ·±ãç†è§£ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹æœçš„ãªåˆ©ç”¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

**ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ©ãƒ•ã¨ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°**

Terraformã¯å†…éƒ¨çš„ã«ã€ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã¨ãã®ä¾å­˜é–¢ä¿‚ã‚’æœ‰å‘éå·¡å›ã‚°ãƒ©ãƒ•ï¼ˆDAGï¼‰ã¨ã—ã¦ç®¡ç†ã—ã¾ã™ã€‚

```hcl
# ä¾å­˜é–¢ä¿‚ã®è‡ªå‹•è§£æ±º
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name = "${var.project}-vpc"
  }
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id  # æš—é»™çš„ãªä¾å­˜é–¢ä¿‚
  
  tags = {
    Name = "${var.project}-igw"
  }
}

resource "aws_subnet" "public" {
  count = length(var.availability_zones)
  
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(aws_vpc.main.cidr_block, 8, count.index)
  availability_zone       = var.availability_zones[count.index]
  map_public_ip_on_launch = true
  
  tags = {
    Name = "${var.project}-public-${var.availability_zones[count.index]}"
    Type = "Public"
  }
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }
  
  tags = {
    Name = "${var.project}-public-rt"
  }
}

resource "aws_route_table_association" "public" {
  count = length(aws_subnet.public)
  
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
  
  # Terraformã¯è‡ªå‹•çš„ã«ä»¥ä¸‹ã®é †åºã§ä½œæˆï¼š
  # 1. VPC
  # 2. Internet Gateway, Subnets (ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½)
  # 3. Route Table
  # 4. Route Table Associations
}
```

### å®Ÿè·µçš„ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆ

å†åˆ©ç”¨å¯èƒ½ã§ä¿å®ˆæ€§ã®é«˜ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¨­è¨ˆã¯ã€å¤§è¦æ¨¡ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ç®¡ç†ã®éµã§ã™ã€‚

**å®Œå…¨ãªVPCãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè£…**

```hcl
# modules/vpc/variables.tf
variable "project_name" {
  description = "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå"
  type        = string
  validation {
    condition     = can(regex("^[a-z0-9-]+$", var.project_name))
    error_message = "Project name must contain only lowercase letters, numbers, and hyphens."
  }
}

variable "environment" {
  description = "ç’°å¢ƒå"
  type        = string
  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }
}

variable "vpc_cidr" {
  description = "VPCã®CIDRãƒ–ãƒ­ãƒƒã‚¯"
  type        = string
  default     = "10.0.0.0/16"
  validation {
    condition     = can(cidrhost(var.vpc_cidr, 0))
    error_message = "VPC CIDR must be a valid IPv4 CIDR block."
  }
}

variable "availability_zones" {
  description = "ä½¿ç”¨ã™ã‚‹AZ"
  type        = list(string)
  default     = []
}

variable "enable_nat_gateway" {
  description = "NAT Gatewayã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹"
  type        = bool
  default     = true
}

variable "single_nat_gateway" {
  description = "NAT Gatewayã‚’1ã¤ã ã‘ä½œæˆã™ã‚‹ã‹"
  type        = bool
  default     = false
}

variable "enable_vpn_gateway" {
  description = "VPN Gatewayã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹"
  type        = bool
  default     = false
}

variable "enable_flow_logs" {
  description = "VPC Flow Logsã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹"
  type        = bool
  default     = true
}

# modules/vpc/main.tf
locals {
  azs = length(var.availability_zones) > 0 ? var.availability_zones : slice(data.aws_availability_zones.available.names, 0, 3)
  
  # ã‚µãƒ–ãƒãƒƒãƒˆè¨ˆç®—
  # ãƒ‘ãƒ–ãƒªãƒƒã‚¯: /24 Ã— AZæ•°
  # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ: /24 Ã— AZæ•°
  # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: /24 Ã— AZæ•°
  public_cidrs   = [for i in range(length(local.azs)) : cidrsubnet(var.vpc_cidr, 8, i)]
  private_cidrs  = [for i in range(length(local.azs)) : cidrsubnet(var.vpc_cidr, 8, i + 10)]
  database_cidrs = [for i in range(length(local.azs)) : cidrsubnet(var.vpc_cidr, 8, i + 20)]
  
  common_tags = {
    Project     = var.project_name
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

data "aws_availability_zones" "available" {
  state = "available"
}

# VPC
resource "aws_vpc" "this" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-vpc"
  })
}

# Internet Gateway
resource "aws_internet_gateway" "this" {
  vpc_id = aws_vpc.this.id
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-igw"
  })
}

# Public Subnets
resource "aws_subnet" "public" {
  count = length(local.azs)
  
  vpc_id                  = aws_vpc.this.id
  cidr_block              = local.public_cidrs[count.index]
  availability_zone       = local.azs[count.index]
  map_public_ip_on_launch = true
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-public-${local.azs[count.index]}"
    Type = "Public"
    "kubernetes.io/role/elb" = "1"  # EKSç”¨ã‚¿ã‚°
  })
}

# Private Subnets
resource "aws_subnet" "private" {
  count = length(local.azs)
  
  vpc_id            = aws_vpc.this.id
  cidr_block        = local.private_cidrs[count.index]
  availability_zone = local.azs[count.index]
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-private-${local.azs[count.index]}"
    Type = "Private"
    "kubernetes.io/role/internal-elb" = "1"  # EKSç”¨ã‚¿ã‚°
  })
}

# Database Subnets
resource "aws_subnet" "database" {
  count = length(local.azs)
  
  vpc_id            = aws_vpc.this.id
  cidr_block        = local.database_cidrs[count.index]
  availability_zone = local.azs[count.index]
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-database-${local.azs[count.index]}"
    Type = "Database"
  })
}

# Elastic IPs for NAT Gateways
resource "aws_eip" "nat" {
  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : length(local.azs)) : 0
  
  domain = "vpc"
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-nat-eip-${count.index + 1}"
  })
  
  depends_on = [aws_internet_gateway.this]
}

# NAT Gateways
resource "aws_nat_gateway" "this" {
  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : length(local.azs)) : 0
  
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-nat-${count.index + 1}"
  })
  
  depends_on = [aws_internet_gateway.this]
}

# Route Tables
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.this.id
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-public-rt"
    Type = "Public"
  })
}

resource "aws_route" "public_internet" {
  route_table_id         = aws_route_table.public.id
  destination_cidr_block = "0.0.0.0/0"
  gateway_id             = aws_internet_gateway.this.id
}

resource "aws_route_table" "private" {
  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : length(local.azs)) : 0
  
  vpc_id = aws_vpc.this.id
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-private-rt-${count.index + 1}"
    Type = "Private"
  })
}

resource "aws_route" "private_nat" {
  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : length(local.azs)) : 0
  
  route_table_id         = aws_route_table.private[count.index].id
  destination_cidr_block = "0.0.0.0/0"
  nat_gateway_id         = var.single_nat_gateway ? aws_nat_gateway.this[0].id : aws_nat_gateway.this[count.index].id
}

# Route Table Associations
resource "aws_route_table_association" "public" {
  count = length(aws_subnet.public)
  
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

resource "aws_route_table_association" "private" {
  count = length(aws_subnet.private)
  
  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = var.enable_nat_gateway ? (var.single_nat_gateway ? aws_route_table.private[0].id : aws_route_table.private[count.index].id) : aws_route_table.public.id
}

resource "aws_route_table_association" "database" {
  count = length(aws_subnet.database)
  
  subnet_id      = aws_subnet.database[count.index].id
  route_table_id = var.enable_nat_gateway ? (var.single_nat_gateway ? aws_route_table.private[0].id : aws_route_table.private[count.index].id) : aws_route_table.public.id
}

# VPC Flow Logs
resource "aws_flow_log" "this" {
  count = var.enable_flow_logs ? 1 : 0
  
  iam_role_arn    = aws_iam_role.flow_logs[0].arn
  log_destination = aws_cloudwatch_log_group.flow_logs[0].arn
  traffic_type    = "ALL"
  vpc_id          = aws_vpc.this.id
  
  tags = merge(local.common_tags, {
    Name = "${var.project_name}-${var.environment}-flow-logs"
  })
}

resource "aws_cloudwatch_log_group" "flow_logs" {
  count = var.enable_flow_logs ? 1 : 0
  
  name              = "/aws/vpc/${var.project_name}-${var.environment}"
  retention_in_days = 30
  
  tags = local.common_tags
}

resource "aws_iam_role" "flow_logs" {
  count = var.enable_flow_logs ? 1 : 0
  
  name = "${var.project_name}-${var.environment}-flow-logs-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "vpc-flow-logs.amazonaws.com"
      }
    }]
  })
  
  tags = local.common_tags
}

resource "aws_iam_role_policy" "flow_logs" {
  count = var.enable_flow_logs ? 1 : 0
  
  name = "${var.project_name}-${var.environment}-flow-logs-policy"
  role = aws_iam_role.flow_logs[0].id
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents",
        "logs:DescribeLogGroups",
        "logs:DescribeLogStreams"
      ]
      Effect = "Allow"
      Resource = "*"
    }]
  })
}

# modules/vpc/outputs.tf
output "vpc_id" {
  description = "VPCã®ID"
  value       = aws_vpc.this.id
}

output "vpc_cidr" {
  description = "VPCã®CIDRãƒ–ãƒ­ãƒƒã‚¯"
  value       = aws_vpc.this.cidr_block
}

output "public_subnet_ids" {
  description = "ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚µãƒ–ãƒãƒƒãƒˆã®IDãƒªã‚¹ãƒˆ"
  value       = aws_subnet.public[*].id
}

output "private_subnet_ids" {
  description = "ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚µãƒ–ãƒãƒƒãƒˆã®IDãƒªã‚¹ãƒˆ"
  value       = aws_subnet.private[*].id
}

output "database_subnet_ids" {
  description = "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µãƒ–ãƒãƒƒãƒˆã®IDãƒªã‚¹ãƒˆ"
  value       = aws_subnet.database[*].id
}

output "nat_gateway_ids" {
  description = "NAT Gatewayã®IDãƒªã‚¹ãƒˆ"
  value       = aws_nat_gateway.this[*].id
}

output "availability_zones" {
  description = "ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹AZã®ãƒªã‚¹ãƒˆ"
  value       = local.azs
}
```

### ç’°å¢ƒåˆ¥æ§‹æˆç®¡ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

**Terraformãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ vs ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ **

```hcl
# ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’ä½¿ã£ãŸç’°å¢ƒç®¡ç†
# åˆ©ç‚¹ï¼šå˜ä¸€ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§è¤‡æ•°ç’°å¢ƒã‚’ç®¡ç†
# æ¬ ç‚¹ï¼šç’°å¢ƒé–“ã®å·®ç•°ãŒå¤§ãã„å ´åˆã«è¤‡é›‘åŒ–

locals {
  # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹åã‹ã‚‰ç’°å¢ƒã‚’åˆ¤å®š
  environment = terraform.workspace
  
  # ç’°å¢ƒåˆ¥è¨­å®š
  instance_types = {
    dev     = "t3.micro"
    staging = "t3.small"
    prod    = "t3.large"
  }
  
  instance_counts = {
    dev     = 1
    staging = 2
    prod    = 4
  }
  
  enable_monitoring = {
    dev     = false
    staging = true
    prod    = true
  }
}

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ™ãƒ¼ã‚¹ã®ç’°å¢ƒç®¡ç†ï¼ˆæ¨å¥¨ï¼‰
# environments/prod/main.tf
module "vpc" {
  source = "../../modules/vpc"
  
  project_name       = var.project_name
  environment        = "prod"
  vpc_cidr          = "10.0.0.0/16"
  enable_nat_gateway = true
  single_nat_gateway = false  # é«˜å¯ç”¨æ€§ã®ãŸã‚å„AZã«NAT Gateway
  enable_flow_logs   = true
}

module "compute" {
  source = "../../modules/compute"
  
  project_name    = var.project_name
  environment     = "prod"
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnet_ids
  instance_type   = "t3.large"
  instance_count  = 4
  
  # æœ¬ç•ªç’°å¢ƒå›ºæœ‰ã®è¨­å®š
  enable_monitoring          = true
  enable_detailed_monitoring = true
  enable_auto_recovery      = true
}

# environments/dev/main.tf
module "vpc" {
  source = "../../modules/vpc"
  
  project_name       = var.project_name
  environment        = "dev"
  vpc_cidr          = "10.100.0.0/16"  # æœ¬ç•ªã¨ç•°ãªã‚‹CIDR
  enable_nat_gateway = true
  single_nat_gateway = true   # ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚1ã¤ã®ã¿
  enable_flow_logs   = false  # é–‹ç™ºç’°å¢ƒã§ã¯ä¸è¦
}
```

### é«˜åº¦ãªTerraformæ©Ÿèƒ½ã®æ´»ç”¨

**Dynamic Blocksã«ã‚ˆã‚‹æŸ”è»Ÿãªè¨­å®š**

```hcl
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—ã®å‹•çš„ãƒ«ãƒ¼ãƒ«ç”Ÿæˆ
variable "security_group_rules" {
  description = "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—ãƒ«ãƒ¼ãƒ«"
  type = list(object({
    type        = string
    from_port   = number
    to_port     = number
    protocol    = string
    cidr_blocks = list(string)
    description = string
  }))
  default = []
}

resource "aws_security_group" "this" {
  name        = "${var.project_name}-${var.environment}-sg"
  description = "Security group for ${var.project_name}"
  vpc_id      = var.vpc_id
  
  # å‹•çš„ãªã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰ãƒ«ãƒ¼ãƒ«
  dynamic "ingress" {
    for_each = [for rule in var.security_group_rules : rule if rule.type == "ingress"]
    
    content {
      from_port   = ingress.value.from_port
      to_port     = ingress.value.to_port
      protocol    = ingress.value.protocol
      cidr_blocks = ingress.value.cidr_blocks
      description = ingress.value.description
    }
  }
  
  # å‹•çš„ãªã‚¢ã‚¦ãƒˆãƒã‚¦ãƒ³ãƒ‰ãƒ«ãƒ¼ãƒ«
  dynamic "egress" {
    for_each = [for rule in var.security_group_rules : rule if rule.type == "egress"]
    
    content {
      from_port   = egress.value.from_port
      to_port     = egress.value.to_port
      protocol    = egress.value.protocol
      cidr_blocks = egress.value.cidr_blocks
      description = egress.value.description
    }
  }
  
  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¢ã‚¦ãƒˆãƒã‚¦ãƒ³ãƒ‰ãƒ«ãƒ¼ãƒ«
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
    description = "Allow all outbound traffic"
  }
  
  tags = merge(var.common_tags, {
    Name = "${var.project_name}-${var.environment}-sg"
  })
}
```

**æ¡ä»¶å¼ã¨forå¼ã®çµ„ã¿åˆã‚ã›**

```hcl
# è¤‡é›‘ãªæ¡ä»¶ã«åŸºã¥ããƒªã‚½ãƒ¼ã‚¹ä½œæˆ
locals {
  # æœ¬ç•ªç’°å¢ƒã®ã¿ãƒãƒ«ãƒAZã€ãã‚Œä»¥å¤–ã¯ã‚·ãƒ³ã‚°ãƒ«AZ
  db_azs = var.environment == "prod" ? var.availability_zones : [var.availability_zones[0]]
  
  # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚°ã®ç”Ÿæˆ
  instance_tags = merge(
    var.common_tags,
    {
      for i in range(var.instance_count) : 
      "Instance${i}" => "web-${var.environment}-${i + 1}"
    }
  )
  
  # ç’°å¢ƒåˆ¥ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
  backup_schedules = {
    prod = {
      frequency = "daily"
      retention = 30
      time      = "03:00"
    }
    staging = {
      frequency = "weekly"
      retention = 7
      time      = "03:00"
    }
    dev = null  # é–‹ç™ºç’°å¢ƒã¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãªã—
  }
}

# RDSã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®æ¡ä»¶ä»˜ãä½œæˆ
resource "aws_rds_cluster" "this" {
  count = var.create_database ? 1 : 0
  
  cluster_identifier = "${var.project_name}-${var.environment}-cluster"
  engine             = "aurora-mysql"
  engine_version     = var.engine_version
  
  # ç’°å¢ƒã«ã‚ˆã£ã¦ç•°ãªã‚‹è¨­å®š
  availability_zones = local.db_azs
  
  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š
  backup_retention_period         = try(local.backup_schedules[var.environment].retention, 1)
  preferred_backup_window        = try(local.backup_schedules[var.environment].time, "03:00-04:00")
  enabled_cloudwatch_logs_exports = var.environment == "prod" ? ["error", "general", "slowquery"] : []
  
  # æœ¬ç•ªç’°å¢ƒã®ã¿æš—å·åŒ–
  storage_encrypted = var.environment == "prod"
  kms_key_id       = var.environment == "prod" ? aws_kms_key.rds[0].arn : null
  
  # æœ¬ç•ªç’°å¢ƒã®ã¿å‰Šé™¤ä¿è­·
  deletion_protection = var.environment == "prod"
  
  dynamic "scaling_configuration" {
    for_each = var.serverless ? [1] : []
    
    content {
      auto_pause               = var.environment != "prod"
      min_capacity            = var.environment == "prod" ? 2 : 1
      max_capacity            = var.environment == "prod" ? 16 : 4
      seconds_until_auto_pause = 300
    }
  }
  
  tags = var.common_tags
}
```

### Terraformã®çŠ¶æ…‹ç®¡ç†ä¸Šç´šãƒ†ã‚¯ãƒ‹ãƒƒã‚¯

**çŠ¶æ…‹ã®åˆ†å‰²ã¨ãƒªãƒ¢ãƒ¼ãƒˆå‚ç…§**

```hcl
# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å±¤ã®çŠ¶æ…‹ã‚’å‚ç…§
data "terraform_remote_state" "network" {
  backend = "s3"
  
  config = {
    bucket = "terraform-state-bucket"
    key    = "env/${var.environment}/network/terraform.tfstate"
    region = "ap-northeast-1"
  }
}

# å…±æœ‰ãƒªã‚½ãƒ¼ã‚¹ã®çŠ¶æ…‹ã‚’å‚ç…§
data "terraform_remote_state" "shared" {
  backend = "s3"
  
  config = {
    bucket = "terraform-state-bucket"
    key    = "global/shared/terraform.tfstate"
    region = "ap-northeast-1"
  }
}

# å‚ç…§ã—ãŸçŠ¶æ…‹ã‹ã‚‰ã®å€¤ã®ä½¿ç”¨
resource "aws_instance" "app" {
  subnet_id              = data.terraform_remote_state.network.outputs.private_subnet_ids[0]
  vpc_security_group_ids = [data.terraform_remote_state.network.outputs.app_security_group_id]
  iam_instance_profile   = data.terraform_remote_state.shared.outputs.ec2_instance_profile_name
  
  # ...
}
```

**çŠ¶æ…‹ã®ç§»è¡Œã¨ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°**

```bash
# æ—¢å­˜ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
terraform import aws_instance.legacy i-1234567890abcdef0

# ãƒªã‚½ãƒ¼ã‚¹ã®ç§»å‹•ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ï¼‰
terraform state mv aws_instance.old aws_instance.new
terraform state mv aws_instance.web module.compute.aws_instance.web

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ç§»å‹•
terraform state mv module.old.aws_vpc.main module.network.aws_vpc.main

# çŠ¶æ…‹ã‹ã‚‰ã®å‰Šé™¤ï¼ˆå®Ÿãƒªã‚½ãƒ¼ã‚¹ã¯å‰Šé™¤ã•ã‚Œãªã„ï¼‰
terraform state rm aws_instance.temp

# çŠ¶æ…‹ã®ä¸€è¦§è¡¨ç¤º
terraform state list

# ç‰¹å®šãƒªã‚½ãƒ¼ã‚¹ã®è©³ç´°è¡¨ç¤º
terraform state show aws_instance.web
```

## 10.3 Ansibleã«ã‚ˆã‚‹æ§‹æˆç®¡ç†ã®åŸºç¤

### æ§‹æˆç®¡ç†ã®æœ¬è³ªã¨å¿…è¦æ€§

Infrastructure as CodeãŒã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã™ã‚‹ã®ã«å¯¾ã—ã€æ§‹æˆç®¡ç†ãƒ„ãƒ¼ãƒ«ã¯ãã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ä¸Šã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‹•ä½œã•ã›ã‚‹ãŸã‚ã®è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚

```yaml
# IaCã¨æ§‹æˆç®¡ç†ã®è²¬ä»»åˆ†æ‹…
Infrastructure as Code (Terraform):
  - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä½œæˆ
  - ã‚µãƒ¼ãƒãƒ¼ã®ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°
  - ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®è¨­å®š
  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆ
  - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—ã®å®šç¾©

Configuration Management (Ansible):
  - OSã®è¨­å®šã¨ãƒãƒ¼ãƒ‰ãƒ‹ãƒ³ã‚°
  - ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
  - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ—ãƒ­ã‚¤
  - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†
  - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨æ¨©é™ã®ç®¡ç†
```

### Ansibleã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ç‰¹å¾´

Ansibleã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ã§å‹•ä½œã—ã€SSHã‚’é€šã˜ã¦ç®¡ç†å¯¾è±¡ãƒãƒ¼ãƒ‰ã‚’åˆ¶å¾¡ã—ã¾ã™ã€‚ã“ã®è¨­è¨ˆã«ã‚ˆã‚Šã€è¿½åŠ ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒä¸è¦ã§ã€æ—¢å­˜ç’°å¢ƒã¸ã®å°å…¥ãŒå®¹æ˜“ã§ã™ã€‚

**Playbookã®æ§‹é€ ã¨è¨­è¨ˆ**

```yaml
---
# site.yml - ãƒã‚¹ã‚¿ãƒ¼Playbook
- name: Common configuration for all servers
  hosts: all
  become: yes
  roles:
    - common
    - security

- name: Configure web servers
  hosts: webservers
  become: yes
  roles:
    - nginx
    - app-deploy
  vars:
    app_version: "{% raw %}{{ lookup('env', 'APP_VERSION') | default('latest', true) }}{% endraw %}"

- name: Configure database servers
  hosts: databases
  become: yes
  roles:
    - postgresql
    - backup

# group_vars/all.yml - å…¨ãƒ›ã‚¹ãƒˆå…±é€šå¤‰æ•°
---
ntp_servers:
  - ntp.nict.jp
  - ntp.jst.mfeed.ad.jp

timezone: Asia/Tokyo

security_ssh_port: 22
security_ssh_password_authentication: "no"
security_ssh_permit_root_login: "no"

# group_vars/webservers.yml - Webã‚µãƒ¼ãƒãƒ¼ç”¨å¤‰æ•°
---
nginx_worker_processes: "{% raw %}{{ ansible_processor_vcpus }}{% endraw %}"
nginx_worker_connections: 2048

app_user: webapp
app_group: webapp
app_home: /var/www/app
app_port: 3000

# group_vars/production.yml - æœ¬ç•ªç’°å¢ƒç”¨å¤‰æ•°
---
nginx_server_tokens: "off"
nginx_ssl_protocols: "TLSv1.2 TLSv1.3"
nginx_ssl_ciphers: "HIGH:!aNULL:!MD5"

enable_monitoring: true
enable_log_shipping: true
```

**é«˜åº¦ãªRoleè¨­è¨ˆ**

```yaml
# roles/nginx/tasks/main.yml
---
- name: Include OS-specific variables
  include_vars: "{% raw %}{{ ansible_os_family }}{% endraw %}.yml"

- name: Install Nginx
  package:
    name: "{% raw %}{{ nginx_package_name }}{% endraw %}"
    state: present
  notify: restart nginx

- name: Create Nginx directories
  file:
    path: "{% raw %}{{ item }}{% endraw %}"
    state: directory
    owner: root
    group: root
    mode: '0755'
  loop:
    - /etc/nginx/sites-available
    - /etc/nginx/sites-enabled
    - /etc/nginx/ssl
    - /var/log/nginx

- name: Generate DH parameters
  openssl_dhparam:
    path: /etc/nginx/ssl/dhparams.pem
    size: 2048
  when: nginx_use_ssl | default(false)

- name: Configure Nginx
  template:
    src: nginx.conf.j2
    dest: /etc/nginx/nginx.conf
    owner: root
    group: root
    mode: '0644'
    validate: 'nginx -t -c %s'
  notify: reload nginx

- name: Configure virtual hosts
  template:
    src: vhost.conf.j2
    dest: "/etc/nginx/sites-available/{% raw %}{{ item.name }}{% endraw %}"
    owner: root
    group: root
    mode: '0644'
  loop: "{% raw %}{{ nginx_vhosts }}{% endraw %}"
  when: nginx_vhosts is defined
  notify: reload nginx

- name: Enable virtual hosts
  file:
    src: "/etc/nginx/sites-available/{% raw %}{{ item.name }}{% endraw %}"
    dest: "/etc/nginx/sites-enabled/{% raw %}{{ item.name }}{% endraw %}"
    state: link
  loop: "{% raw %}{{ nginx_vhosts }}{% endraw %}"
  when: nginx_vhosts is defined
  notify: reload nginx

- name: Remove default site
  file:
    path: /etc/nginx/sites-enabled/default
    state: absent
  notify: reload nginx

- name: Ensure Nginx is running
  systemd:
    name: nginx
    state: started
    enabled: yes
    daemon_reload: yes

# roles/nginx/templates/nginx.conf.j2
user `{{ nginx_user }}`;
worker_processes `{{ nginx_worker_processes }}`;
pid /run/nginx.pid;

events {
    worker_connections `{{ nginx_worker_connections }}`;
    multi_accept on;
    use epoll;
}

http {
    # åŸºæœ¬è¨­å®š
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_tokens `{{ nginx_server_tokens | default('on') }}`;
    
    # MIME types
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # SSLè¨­å®š
    {% if nginx_use_ssl | default(false) %}
    ssl_protocols `{{ nginx_ssl_protocols }}`;
    ssl_ciphers `{{ nginx_ssl_ciphers }}`;
    ssl_prefer_server_ciphers on;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    ssl_stapling on;
    ssl_stapling_verify on;
    {% endif %}
    
    # ãƒ­ã‚°è¨­å®š
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;
    
    # Gzipåœ§ç¸®
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript application/json application/javascript application/xml+rss application/rss+xml application/atom+xml image/svg+xml;
    
    # ãƒãƒ¼ãƒãƒ£ãƒ«ãƒ›ã‚¹ãƒˆè¨­å®š
    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;
}

# roles/nginx/handlers/main.yml
---
- name: restart nginx
  systemd:
    name: nginx
    state: restarted
  when: nginx_restart_on_change | default(true)

- name: reload nginx
  systemd:
    name: nginx
    state: reloaded
  when: nginx_reload_on_change | default(true)

- name: validate nginx configuration
  command: nginx -t
  changed_when: false
```

### å‹•çš„ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªã¨ã‚¯ãƒ©ã‚¦ãƒ‰çµ±åˆ

ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã¯ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒå‹•çš„ã«ä½œæˆãƒ»å‰Šé™¤ã•ã‚Œã‚‹ãŸã‚ã€é™çš„ãªã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ç®¡ç†ãŒå›°é›£ã§ã™ã€‚

```python
#!/usr/bin/env python3
# dynamic_inventory_aws.py

import json
import boto3
from collections import defaultdict

class AWSInventory:
    def __init__(self):
        self.inventory = defaultdict(lambda: {'hosts': [], 'vars': {}})
        self.inventory['_meta'] = {'hostvars': {}}
        
    def get_instances(self):
        """EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã—ã¦ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªã‚’æ§‹ç¯‰"""
        ec2 = boto3.client('ec2', region_name='ap-northeast-1')
        
        # å®Ÿè¡Œä¸­ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
        response = ec2.describe_instances(
            Filters=[
                {'Name': 'instance-state-name', 'Values': ['running']}
            ]
        )
        
        for reservation in response['Reservations']:
            for instance in reservation['Instances']:
                self._add_instance(instance)
                
    def _add_instance(self, instance):
        """ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªã«è¿½åŠ """
        instance_id = instance['InstanceId']
        
        # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆIPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ä½¿ç”¨ï¼ˆVPCå†…é€šä¿¡ï¼‰
        private_ip = instance.get('PrivateIpAddress')
        if not private_ip:
            return
            
        # ã‚¿ã‚°ã‹ã‚‰ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ±ºå®š
        tags = {tag['Key']: tag['Value'] for tag in instance.get('Tags', [])}
        
        # ç’°å¢ƒã‚°ãƒ«ãƒ¼ãƒ—
        environment = tags.get('Environment', 'unknown')
        self.inventory[environment]['hosts'].append(private_ip)
        
        # å½¹å‰²ã‚°ãƒ«ãƒ¼ãƒ—
        role = tags.get('Role', 'unknown')
        self.inventory[role]['hosts'].append(private_ip)
        
        # çµ„ã¿åˆã‚ã›ã‚°ãƒ«ãƒ¼ãƒ—
        combined_group = f"{environment}_{role}"
        self.inventory[combined_group]['hosts'].append(private_ip)
        
        # ãƒ›ã‚¹ãƒˆå¤‰æ•°
        self.inventory['_meta']['hostvars'][private_ip] = {
            'instance_id': instance_id,
            'instance_type': instance['InstanceType'],
            'availability_zone': instance['Placement']['AvailabilityZone'],
            'private_dns_name': instance.get('PrivateDnsName', ''),
            'tags': tags,
            'ansible_host': private_ip,
            'ansible_ssh_private_key_file': f"~/.ssh/{environment}.pem"
        }
        
        # ç‰¹åˆ¥ãªè¨­å®š
        if role == 'bastion':
            self.inventory['_meta']['hostvars'][private_ip]['ansible_ssh_common_args'] = '-o ProxyCommand="none"'
        else:
            # è¸ã¿å°çµŒç”±ã®æ¥ç¶š
            bastion_ip = self._get_bastion_ip(environment)
            if bastion_ip:
                self.inventory['_meta']['hostvars'][private_ip]['ansible_ssh_common_args'] = \
                    f'-o ProxyCommand="ssh -W %h:%p -q ubuntu@{bastion_ip}"'
    
    def _get_bastion_ip(self, environment):
        """è¸ã¿å°ã‚µãƒ¼ãƒãƒ¼ã®IPã‚’å–å¾—"""
        bastion_group = f"{environment}_bastion"
        if bastion_group in self.inventory and self.inventory[bastion_group]['hosts']:
            return self.inventory[bastion_group]['hosts'][0]
        return None
        
    def get_inventory(self):
        """ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªã‚’JSONå½¢å¼ã§è¿”ã™"""
        self.get_instances()
        return json.dumps(self.inventory, indent=2)

if __name__ == '__main__':
    inventory = AWSInventory()
    print(inventory.get_inventory())
```

### å†ªç­‰æ€§ã®ç¢ºä¿ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

å†ªç­‰æ€§ã¯æ§‹æˆç®¡ç†ã«ãŠã„ã¦æœ€ã‚‚é‡è¦ãªæ¦‚å¿µã§ã™ã€‚åŒã˜Playbookã‚’ä½•åº¦å®Ÿè¡Œã—ã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ãŒåŒã˜ã«ãªã‚‹ã“ã¨ã‚’ä¿è¨¼ã—ã¾ã™ã€‚

```yaml
# å†ªç­‰æ€§ã‚’ä¿è¨¼ã™ã‚‹æ›¸ãæ–¹ã®ä¾‹
---
- name: å†ªç­‰æ€§ã®ã‚ã‚‹ã‚¿ã‚¹ã‚¯ä¾‹
  hosts: all
  become: yes
  
  tasks:
    # GOOD: å†ªç­‰æ€§ã‚ã‚Š - ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚Œã°å¤‰æ›´ãªã—
    - name: Create application directory
      file:
        path: /opt/myapp
        state: directory
        owner: myapp
        group: myapp
        mode: '0755'
    
    # GOOD: å†ªç­‰æ€§ã‚ã‚Š - è¡ŒãŒæ—¢ã«å­˜åœ¨ã™ã‚Œã°è¿½åŠ ã—ãªã„
    - name: Add configuration line
      lineinfile:
        path: /etc/sysctl.conf
        line: 'vm.swappiness=10'
        state: present
    
    # GOOD: å†ªç­‰æ€§ã‚ã‚Š - ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæ—¢ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãªã‚‰ä½•ã‚‚ã—ãªã„
    - name: Install required packages
      package:
        name:
          - git
          - python3-pip
          - nginx
        state: present
    
    # BAD: å†ªç­‰æ€§ãªã— - å®Ÿè¡Œã™ã‚‹ãŸã³ã«ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜ã•ã‚Œã‚‹
    - name: Append to log file (éæ¨å¥¨)
      shell: echo "Deployment at $(date)" >> /var/log/deploy.log
    
    # GOOD: ä¸Šè¨˜ã®å†ªç­‰æ€§ã®ã‚ã‚‹ä»£æ›¿æ¡ˆ
    - name: Record deployment
      copy:
        content: "Last deployment: `{{ ansible_date_time.iso8601 }}`\n"
        dest: /var/log/last_deploy.log
        owner: root
        group: root
        mode: '0644'
    
    # æ¡ä»¶ä»˜ãå®Ÿè¡Œã§å†ªç­‰æ€§ã‚’ç¢ºä¿
    - name: Initialize database
      command: /opt/myapp/bin/init_db.sh
      args:
        creates: /opt/myapp/db/.initialized
      # .initializedãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å®Ÿè¡Œã—ãªã„
    
    # ãƒã‚§ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã®å‹•ä½œç¢ºèª
    - name: Configure service
      template:
        src: myapp.service.j2
        dest: /etc/systemd/system/myapp.service
      register: service_config
      check_mode: yes
      
    - name: Reload systemd if needed
      systemd:
        daemon_reload: yes
      when: service_config.changed
```

### ã‚»ã‚­ãƒ¥ã‚¢ãªå¤‰æ•°ç®¡ç†

æ©Ÿå¯†æƒ…å ±ã‚’å®‰å…¨ã«ç®¡ç†ã™ã‚‹ãŸã‚ã€Ansible Vaultã‚’æ´»ç”¨ã—ã¾ã™ã€‚

```yaml
# Vaultæš—å·åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
# ansible-vault create vars/secrets.yml

# å¹³æ–‡ã® secrets.yml
---
database_password: "super-secret-password"
api_keys:
  stripe: "sk_live_..."
  aws_access_key: "AKIA..."
  aws_secret_key: "..."

# æš—å·åŒ–å¾Œ
$ANSIBLE_VAULT;1.1;AES256
39613836386435386...ï¼ˆæš—å·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼‰

# Playbookã§ã®ä½¿ç”¨
---
- name: Deploy application with secrets
  hosts: webservers
  vars_files:
    - vars/common.yml
    - vars/secrets.yml  # Vaultæš—å·åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
  
  tasks:
    - name: Create database configuration
      template:
        src: database.yml.j2
        dest: "`{{ app_home }}`/config/database.yml"
        owner: "`{{ app_user }}`"
        group: "`{{ app_group }}`"
        mode: '0600'  # æ©Ÿå¯†æƒ…å ±ã®ãŸã‚å³æ ¼ãªæ¨©é™
      no_log: true    # ãƒ­ã‚°ã«æ©Ÿå¯†æƒ…å ±ã‚’å‡ºåŠ›ã—ãªã„

# templates/database.yml.j2
production:
  adapter: postgresql
  encoding: unicode
  database: `{{ database_name }}`
  pool: `{{ database_pool | default(5) }}`
  username: `{{ database_user }}`
  password: `{{ database_password }}`  # Vaultã‹ã‚‰å–å¾—
  host: `{{ database_host }}`
  port: `{{ database_port | default(5432) }}`

# å®Ÿè¡Œæ™‚
# ansible-playbook -i inventory site.yml --ask-vault-pass
# ã¾ãŸã¯
# ansible-playbook -i inventory site.yml --vault-password-file ~/.vault_pass
```

## 10.4 CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ãƒ‡ãƒ—ãƒ­ã‚¤è‡ªå‹•åŒ–

### CI/CDã®æœ¬è³ªã¨ä¾¡å€¤

ç¶™ç¶šçš„ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆCIï¼‰ã¨ç¶™ç¶šçš„ãƒ‡ãƒªãƒãƒªãƒ¼ï¼ˆCDï¼‰ã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã¨å“è³ªã‚’ä¸¡ç«‹ã•ã›ã‚‹ãŸã‚ã®æ–¹æ³•è«–ã§ã™ã€‚ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®ã‚³ãƒ¼ãƒ‰åŒ–ã«ã‚ˆã‚Šã€ã“ã‚Œã‚‰ã®å®Ÿè·µã‚’ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†ã«ã‚‚é©ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

**CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆåŸå‰‡**

```yaml
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆã®åŸå‰‡:
  é«˜é€Ÿãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯:
    - å•é¡Œã®æ—©æœŸç™ºè¦‹
    - 10åˆ†ä»¥å†…ã®åŸºæœ¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
    - æ®µéšçš„ãªè©³ç´°æ¤œè¨¼
    
  è‡ªå‹•åŒ–ã®å¾¹åº•:
    - æ‰‹å‹•ãƒ—ãƒ­ã‚»ã‚¹ã®æ’é™¤
    - ä¸€è²«æ€§ã®ç¢ºä¿
    - ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ã‚¨ãƒ©ãƒ¼ã®é˜²æ­¢
    
  æ®µéšçš„ãªãƒªã‚¹ã‚¯ç®¡ç†:
    - ç’°å¢ƒã‚’æ®µéšçš„ã«æ˜‡æ ¼
    - å„æ®µéšã§ã®æ¤œè¨¼å¼·åŒ–
    - ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯èƒ½æ€§ã®ç¢ºä¿
    
  ç›£æŸ»è¨¼è·¡:
    - ã™ã¹ã¦ã®å¤‰æ›´ã®è¨˜éŒ²
    - æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–
    - ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å¯¾å¿œ
```

### åŒ…æ‹¬çš„ãªCI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…

**GitHub Actionsã«ã‚ˆã‚‹å®Œå…¨è‡ªå‹•åŒ–**

```yaml
# .github/workflows/infrastructure-pipeline.yml
name: Infrastructure CI/CD Pipeline

on:
  pull_request:
    branches: [main]
    paths:
      - 'terraform/**'
      - 'ansible/**'
  push:
    branches: [main]
    paths:
      - 'terraform/**'
      - 'ansible/**'

env:
  TF_VERSION: '1.5.0'
  ANSIBLE_VERSION: '2.15.0'
  AWS_REGION: 'ap-northeast-1'

jobs:
  # 1. é™çš„è§£æã¨lint
  static-analysis:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: `${{ env.TF_VERSION }}`
          
      - name: Terraform Format Check
        run: |
          cd terraform
          terraform fmt -check -recursive
          
      - name: Terraform Validate
        run: |
          cd terraform
          for dir in $(find . -type f -name "*.tf" -exec dirname {} \; | sort -u); do
            echo "Validating $dir"
            (cd "$dir" && terraform init -backend=false && terraform validate)
          done
          
      - name: TFLint
        uses: terraform-linters/setup-tflint@v3
        with:
          tflint_version: latest
          
      - name: Run TFLint
        run: |
          cd terraform
          tflint --init
          tflint --recursive
          
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install Ansible and ansible-lint
        run: |
          pip install ansible=`${{ env.ANSIBLE_VERSION }}` ansible-lint
          
      - name: Ansible Lint
        run: |
          cd ansible
          ansible-lint

  # 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Checkov Security Scan
        id: checkov
        uses: bridgecrewio/checkov-action@master
        with:
          directory: terraform/
          framework: terraform
          output_format: sarif
          output_file_path: reports/checkov.sarif
          
      - name: Upload Checkov results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: reports/checkov.sarif
          
      - name: Terrascan
        run: |
          wget https://github.com/tenable/terrascan/releases/latest/download/terrascan_Linux_x86_64.tar.gz
          tar -xf terrascan_Linux_x86_64.tar.gz
          ./terrascan scan -i terraform -d terraform/
          
      - name: Secrets Scan
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: `${{ github.event.repository.default_branch }}`
          head: HEAD

  # 3. ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š
  cost-estimation:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    permissions:
      contents: read
      pull-requests: write
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Infracost
        uses: infracost/setup-infracost@v2
        with:
          api-key: `${{ secrets.INFRACOST_API_KEY }}`
          
      - name: Generate Infracost JSON
        run: |
          cd terraform/environments/prod
          infracost breakdown --path . \
            --format json \
            --out-file /tmp/infracost.json
            
      - name: Post Infracost comment
        uses: infracost/infracost-comment@v1
        with:
          path: /tmp/infracost.json
          behavior: update

  # 4. Terraformãƒ—ãƒ©ãƒ³ï¼ˆPRæ™‚ï¼‰
  terraform-plan:
    needs: [static-analysis, security-scan]
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    strategy:
      matrix:
        environment: [dev, staging, prod]
    permissions:
      contents: read
      pull-requests: write
      id-token: write
      
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: `${{ secrets[format('AWS_{0}_ROLE', matrix.environment)] }}`
          aws-region: `${{ env.AWS_REGION }}`
          
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: `${{ env.TF_VERSION }}`
          
      - name: Terraform Init
        run: |
          cd terraform/environments/`${{ matrix.environment }}`
          terraform init
          
      - name: Terraform Plan
        id: plan
        run: |
          cd terraform/environments/`${{ matrix.environment }}`
          terraform plan -out=tfplan -no-color | tee plan_output.txt
          
      - name: Create Plan Summary
        uses: actions/github-script@v6
        if: github.event_name == 'pull_request'
        with:
          script: |
            const output = `#### Terraform Plan - `${{ matrix.environment }}` ğŸ“‹
            
            <details><summary>Show Plan</summary>
            
            \`\`\`terraform
            ${require('fs').readFileSync('terraform/environments/`${{ matrix.environment }}`/plan_output.txt', 'utf8')}
            \`\`\`
            
            </details>
            
            *Pushed by: @`${{ github.actor }}{% endraw %}, Action: \`{% raw %}${{ github.event_name }}`\`*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

  # 5. çµ±åˆãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ§‹ç¯‰
  integration-test:
    needs: terraform-plan
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: `${{ secrets.AWS_TEST_ROLE }}`
          aws-region: `${{ env.AWS_REGION }}`
          
      - name: Create Test Environment
        id: test-env
        run: |
          cd terraform/environments/test
          terraform init
          terraform apply -auto-approve \
            -var="pr_number=`${{ github.event.pull_request.number }}`"
          
          # å‡ºåŠ›å€¤ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®š
          echo "test_url=$(terraform output -raw test_environment_url)" >> $GITHUB_OUTPUT
          
      - name: Run Integration Tests
        run: |
          cd tests/integration
          npm install
          npm run test:integration -- \
            --url "`${{ steps.test-env.outputs.test_url }}`"
            
      - name: Run E2E Tests
        uses: cypress-io/github-action@v5
        with:
          config: baseUrl=`${{ steps.test-env.outputs.test_url }}`
          spec: tests/e2e/**/*.cy.js
          
      - name: Cleanup Test Environment
        if: always()
        run: |
          cd terraform/environments/test
          terraform destroy -auto-approve \
            -var="pr_number=`${{ github.event.pull_request.number }}`"

  # 6. ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤
  deploy-infrastructure:
    needs: [static-analysis, security-scan, cost-estimation]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    strategy:
      matrix:
        environment: [dev, staging, prod]
      max-parallel: 1  # ç’°å¢ƒã‚’é †ç•ªã«ãƒ‡ãƒ—ãƒ­ã‚¤
    environment: `${{ matrix.environment }}`
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: `${{ secrets[format('AWS_{0}_ROLE', matrix.environment)] }}`
          aws-region: `${{ env.AWS_REGION }}`
          
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: `${{ env.TF_VERSION }}`
          
      - name: Terraform Apply
        run: |
          cd terraform/environments/`${{ matrix.environment }}`
          terraform init
          terraform apply -auto-approve
          
      - name: Run Smoke Tests
        run: |
          cd tests/smoke
          ./run_smoke_tests.sh `${{ matrix.environment }}`
          
      - name: Update Documentation
        if: matrix.environment == 'prod'
        run: |
          cd terraform/environments/`${{ matrix.environment }}`
          terraform show -json > ../../../docs/infrastructure-state.json
          terraform graph | dot -Tpng > ../../../docs/infrastructure-diagram.png

  # 7. æ§‹æˆç®¡ç†ã®é©ç”¨
  configure-servers:
    needs: deploy-infrastructure
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    strategy:
      matrix:
        environment: [dev, staging, prod]
      max-parallel: 1
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install Ansible
        run: |
          pip install ansible=`${{ env.ANSIBLE_VERSION }}`
          pip install boto3  # AWSå‹•çš„ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªç”¨
          
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: `${{ secrets[format('AWS_{0}_ROLE', matrix.environment)] }}`
          aws-region: `${{ env.AWS_REGION }}`
          
      - name: Run Ansible Playbook
        env:
          ANSIBLE_HOST_KEY_CHECKING: False
          ANSIBLE_VAULT_PASSWORD: `${{ secrets.ANSIBLE_VAULT_PASSWORD }}`
        run: |
          cd ansible
          
          # Vault ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
          echo "$ANSIBLE_VAULT_PASSWORD" > .vault_pass
          
          # å‹•çš„ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªã‚’ä½¿ç”¨ã—ã¦Playbookå®Ÿè¡Œ
          ansible-playbook -i inventory/aws_ec2.yml \
            site.yml \
            --limit "`${{ matrix.environment }}`" \
            --vault-password-file .vault_pass
            
          # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
          rm -f .vault_pass

  # 8. ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆã®è¨­å®š
  setup-monitoring:
    needs: configure-servers
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure Datadog
        env:
          DD_API_KEY: `${{ secrets.DATADOG_API_KEY }}`
          DD_APP_KEY: `${{ secrets.DATADOG_APP_KEY }}`
        run: |
          cd monitoring/datadog
          ./setup_monitors.sh
          
      - name: Configure PagerDuty
        env:
          PAGERDUTY_TOKEN: `${{ secrets.PAGERDUTY_TOKEN }}`
        run: |
          cd monitoring/pagerduty
          ./setup_escalation_policies.sh
```

### ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥ã®å®Ÿè£…

**Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ**

```hcl
# terraform/modules/blue-green/main.tf
variable "active_environment" {
  description = "ç¾åœ¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªç’°å¢ƒ (blue/green)"
  type        = string
  default     = "blue"
}

locals {
  environments = toset(["blue", "green"])
  inactive_environment = var.active_environment == "blue" ? "green" : "blue"
}

# ä¸¡ç’°å¢ƒã®ASG
resource "aws_autoscaling_group" "app" {
  for_each = local.environments
  
  name                = "${var.project_name}-${each.key}"
  vpc_zone_identifier = var.private_subnet_ids
  target_group_arns   = each.key == var.active_environment ? [aws_lb_target_group.app.arn] : []
  health_check_type   = "ELB"
  health_check_grace_period = 300
  
  min_size         = each.key == var.active_environment ? var.min_size : 0
  max_size         = var.max_size
  desired_capacity = each.key == var.active_environment ? var.desired_capacity : 0
  
  launch_template {
    id      = aws_launch_template.app[each.key].id
    version = "$Latest"
  }
  
  tag {
    key                 = "Name"
    value               = "${var.project_name}-${each.key}"
    propagate_at_launch = true
  }
  
  tag {
    key                 = "Environment"
    value               = each.key
    propagate_at_launch = true
  }
}

# åˆ‡ã‚Šæ›¿ãˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
resource "local_file" "switch_environment" {
  filename = "${path.module}/switch_environment.sh"
  content  = <<-EOF
    #!/bin/bash
    set -e
    
    CURRENT="${var.active_environment}"
    TARGET="${local.inactive_environment}"
    
    echo "Switching from $CURRENT to $TARGET environment..."
    
    # 1. æ–°ç’°å¢ƒã‚’èµ·å‹•
    aws autoscaling set-desired-capacity \
      --auto-scaling-group-name ${var.project_name}-$TARGET \
      --desired-capacity ${var.desired_capacity}
    
    # 2. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å¾…ã¤
    aws autoscaling wait \
      --auto-scaling-group-name ${var.project_name}-$TARGET \
      --query "length(AutoScalingGroups[0].Instances[?HealthStatus=='Healthy'])" \
      --desired-value ${var.desired_capacity}
    
    # 3. ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’åˆ‡ã‚Šæ›¿ãˆ
    terraform apply -var="active_environment=$TARGET" -auto-approve
    
    # 4. æ—§ç’°å¢ƒã‚’åœæ­¢
    aws autoscaling set-desired-capacity \
      --auto-scaling-group-name ${var.project_name}-$CURRENT \
      --desired-capacity 0
    
    echo "Environment switch completed!"
  EOF
  
  file_permission = "0755"
}
```

**ã‚«ãƒŠãƒªã‚¢ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ**

```yaml
# kubernetes/canary-deployment.yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp
  ports:
    - port: 80
      targetPort: 8080
---
# å®‰å®šç‰ˆï¼ˆ90%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ï¼‰
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-stable
spec:
  replicas: 9
  selector:
    matchLabels:
      app: myapp
      version: stable
  template:
    metadata:
      labels:
        app: myapp
        version: stable
    spec:
      containers:
      - name: myapp
        image: myapp:v1.0.0
        ports:
        - containerPort: 8080
---
# ã‚«ãƒŠãƒªã‚¢ç‰ˆï¼ˆ10%ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ï¼‰
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-canary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
      version: canary
  template:
    metadata:
      labels:
        app: myapp
        version: canary
    spec:
      containers:
      - name: myapp
        image: myapp:v2.0.0
        ports:
        - containerPort: 8080

---
# è‡ªå‹•åŒ–ã•ã‚ŒãŸã‚«ãƒŠãƒªã‚¢åˆ†æ
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: myapp
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  service:
    port: 80
  analysis:
    interval: 1m
    threshold: 10
    maxWeight: 50
    stepWeight: 5
    metrics:
    - name: request-success-rate
      thresholdRange:
        min: 99
      interval: 1m
    - name: request-duration
      thresholdRange:
        max: 500
      interval: 1m
    webhooks:
    - name: load-test
      url: http://loadtester/
      metadata:
        cmd: "hey -z 1m -c 10 -q 20 http://myapp/"
```

### GitOpsã«ã‚ˆã‚‹å®£è¨€çš„ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```yaml
# argocd/application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: infrastructure
  namespace: argocd
spec:
  project: default
  
  source:
    repoURL: https://github.com/myorg/infrastructure
    targetRevision: HEAD
    path: kubernetes/overlays/production
    
  destination:
    server: https://kubernetes.default.svc
    namespace: production
    
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: false
    syncOptions:
    - CreateNamespace=true
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m
        
  # Terraformé€£æº
  initContainers:
  - name: terraform-apply
    image: hashicorp/terraform:1.5.0
    command:
    - sh
    - -c
    - |
      cd /terraform
      terraform init
      terraform apply -auto-approve
    volumeMounts:
    - name: terraform-config
      mountPath: /terraform
      
  # Post-sync hooks
  postSync:
  - name: smoke-tests
    container:
      image: postman/newman
      command: ["newman", "run", "smoke-tests.json"]
  - name: notify-slack
    container:
      image: curlimages/curl
      command: 
      - sh
      - -c
      - |
        curl -X POST $SLACK_WEBHOOK \
          -H 'Content-type: application/json' \
          -d '{"text":"Deployment completed successfully"}'
```

Infrastructure as Code ã¨è‡ªå‹•åŒ–ã¯ã€ç¾ä»£ã®ã‚¯ãƒ©ã‚¦ãƒ‰é‹ç”¨ã®åŸºç›¤ã§ã™ã€‚å®£è¨€çš„ãªç®¡ç†ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€è‡ªå‹•åŒ–ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ä¿¡é ¼æ€§ãŒé«˜ãã€ç›£æŸ»å¯èƒ½ã§ã€åŠ¹ç‡çš„ãªã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£é‹ç”¨ãŒå®Ÿç¾ã§ãã¾ã™ã€‚

é‡è¦ãªã®ã¯ã€ã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã¨æ‰‹æ³•ã‚’æ®µéšçš„ã«å°å…¥ã—ã€çµ„ç¹”ã®æˆç†Ÿåº¦ã«åˆã‚ã›ã¦é€²åŒ–ã•ã›ã¦ã„ãã“ã¨ã§ã™ã€‚å®Œç’§ã‚’æ±‚ã‚ã‚‹ã®ã§ã¯ãªãã€ç¶™ç¶šçš„ãªæ”¹å–„ã‚’é€šã˜ã¦ã€ã‚ˆã‚Šè‰¯ã„ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ç®¡ç†ã‚’å®Ÿç¾ã—ã¦ã„ãã“ã¨ãŒæˆåŠŸã¸ã®éµã¨ãªã‚Šã¾ã™ã€‚
---

[ç¬¬11ç« ](../chapter-chapter11/index.md)ã¸é€²ã‚€
