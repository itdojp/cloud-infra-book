---
title: "ç¬¬8ç« ï¼šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ç½å®³å¾©æ—§æˆ¦ç•¥"
chapter: chapter08
layout: book
---

# ç¬¬8ç« ï¼šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ç½å®³å¾©æ—§æˆ¦ç•¥

## 8.1 ã‚¯ãƒ©ã‚¦ãƒ‰ã«ãŠã‘ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ç½å®³å¾©æ—§ã®é‡è¦æ€§

### ç½å®³å¾©æ—§ã®åŸºæœ¬æ¦‚å¿µ

ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã«ãŠã‘ã‚‹ç½å®³å¾©æ—§ã¯ã€å¾“æ¥ã®ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ç’°å¢ƒã¨æ¯”è¼ƒã—ã¦ã€ã‚ˆã‚Šè¤‡é›‘ã§å¤šå±¤çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚ã‚¯ãƒ©ã‚¦ãƒ‰ã®åˆ†æ•£æ€§ã¨ä»®æƒ³åŒ–ã®ç‰¹æ€§ã¯ã€æ–°ã—ã„æ©Ÿä¼šã¨èª²é¡Œã®ä¸¡æ–¹ã‚’æä¾›ã—ã¾ã™ã€‚

**RPOï¼ˆRecovery Point Objectiveï¼‰ã¨RTOï¼ˆRecovery Time Objectiveï¼‰ã®å®šç¾©**

ç½å®³å¾©æ—§è¨ˆç”»ã®åŸºç›¤ã¨ãªã‚‹2ã¤ã®é‡è¦ãªæŒ‡æ¨™ï¼š

```yaml
RPO (Recovery Point Objective):
  å®šç¾©: è¨±å®¹å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿æå¤±ã®æ™‚é–“
  ä¾‹:
    - RPO = 1æ™‚é–“: æœ€å¤§1æ™‚é–“åˆ†ã®ãƒ‡ãƒ¼ã‚¿æå¤±ã‚’è¨±å®¹
    - RPO = 0åˆ†: ãƒ‡ãƒ¼ã‚¿æå¤±ã‚’ä¸€åˆ‡è¨±å®¹ã—ãªã„
    
RTO (Recovery Time Objective):
  å®šç¾©: è¨±å®¹å¯èƒ½ãªå¾©æ—§æ™‚é–“
  ä¾‹:
    - RTO = 4æ™‚é–“: ç½å®³ç™ºç”Ÿã‹ã‚‰4æ™‚é–“ä»¥å†…ã«å¾©æ—§å®Œäº†
    - RTO = 15åˆ†: 15åˆ†ä»¥å†…ã«ã‚µãƒ¼ãƒ“ã‚¹å¾©æ—§
```

**ç½å®³ã®åˆ†é¡ã¨å½±éŸ¿åº¦**

```yaml
ç½å®³ãƒ¬ãƒ™ãƒ«åˆ†é¡:
  Level 1 - è»½å¾®ãªéšœå®³:
    - å½±éŸ¿: ä¸€éƒ¨æ©Ÿèƒ½ã®åœæ­¢
    - å¾©æ—§æ™‚é–“: æ•°åˆ†ï½æ•°æ™‚é–“
    - å¯¾å¿œ: è‡ªå‹•å¾©æ—§ã€ç›£è¦–ãƒãƒ¼ãƒ å¯¾å¿œ
    
  Level 2 - é‡å¤§ãªéšœå®³:
    - å½±éŸ¿: ã‚µãƒ¼ãƒ“ã‚¹å…¨åœæ­¢
    - å¾©æ—§æ™‚é–“: æ•°æ™‚é–“ï½1æ—¥
    - å¯¾å¿œ: ç·Šæ€¥å¯¾å¿œãƒãƒ¼ãƒ å¬é›†
    
  Level 3 - å¤§è¦æ¨¡ç½å®³:
    - å½±éŸ¿: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å…¨ä½“ã®åœæ­¢
    - å¾©æ—§æ™‚é–“: 1æ—¥ï½æ•°é€±é–“
    - å¯¾å¿œ: äº‹æ¥­ç¶™ç¶šè¨ˆç”»ï¼ˆBCPï¼‰ç™ºå‹•
```

### ã‚¯ãƒ©ã‚¦ãƒ‰ç½å®³å¾©æ—§ã®åˆ©ç‚¹

**å¾“æ¥ã®DRã¨ã®æ¯”è¼ƒ**

```yaml
å¾“æ¥ã®DR vs ã‚¯ãƒ©ã‚¦ãƒ‰DR:
  åˆæœŸæŠ•è³‡:
    å¾“æ¥: æ•°å„„å††ï¼ˆDRå°‚ç”¨ã‚»ãƒ³ã‚¿ãƒ¼æ§‹ç¯‰ï¼‰
    ã‚¯ãƒ©ã‚¦ãƒ‰: æ•°ä¸‡å††ï¼ˆè¨­å®šã¨ãƒ†ã‚¹ãƒˆï¼‰
    
  ç¶­æŒè²»ç”¨:
    å¾“æ¥: æœˆé¡æ•°åƒä¸‡å††ï¼ˆäººä»¶è²»ã€è¨­å‚™è²»ï¼‰
    ã‚¯ãƒ©ã‚¦ãƒ‰: æœˆé¡æ•°åä¸‡å††ï½ï¼ˆä½¿ç”¨é‡ã«å¿œã˜ã¦ï¼‰
    
  ãƒ†ã‚¹ãƒˆé »åº¦:
    å¾“æ¥: å¹´1-2å›ï¼ˆé«˜ã‚³ã‚¹ãƒˆã®ãŸã‚ï¼‰
    ã‚¯ãƒ©ã‚¦ãƒ‰: æœˆ1å›ä»¥ä¸Šï¼ˆä½ã‚³ã‚¹ãƒˆã§å®Ÿæ–½å¯èƒ½ï¼‰
    
  åœ°ç†çš„åˆ†æ•£:
    å¾“æ¥: é™å®šçš„ï¼ˆç‰©ç†çš„åˆ¶ç´„ï¼‰
    ã‚¯ãƒ©ã‚¦ãƒ‰: ã‚°ãƒ­ãƒ¼ãƒãƒ«ï¼ˆè¤‡æ•°ãƒªãƒ¼ã‚¸ãƒ§ãƒ³æ´»ç”¨ï¼‰
```

## 8.2 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã®è¨­è¨ˆ

### 3-2-1ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ«ãƒ¼ãƒ«ã®ç¾ä»£åŒ–

å¾“æ¥ã®3-2-1ãƒ«ãƒ¼ãƒ«ã‚’ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã«é©å¿œã•ã›ãŸæˆ¦ç•¥ï¼š

```yaml
æ‹¡å¼µ3-2-1-1ãƒ«ãƒ¼ãƒ«:
  3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼:
    - æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ—ãƒ©ã‚¤ãƒãƒªï¼‰
    - ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆåŒä¸€ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    - ãƒªãƒ¢ãƒ¼ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆç•°ãªã‚‹ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    
  2ã¤ã®ç•°ãªã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢:
    - ãƒ‡ã‚£ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ï¼ˆé«˜é€Ÿã‚¢ã‚¯ã‚»ã‚¹ï¼‰
    - ãƒ†ãƒ¼ãƒ—/ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆé•·æœŸä¿å­˜ï¼‰
    
  1ã¤ã®ã‚ªãƒ•ã‚µã‚¤ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:
    - åœ°ç†çš„ã«åˆ†æ•£ã—ãŸå ´æ‰€
    - ç•°ãªã‚‹ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰ï¼‰
    
  +1ã¤ã®ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:
    - å¤‰æ›´ãƒ»å‰Šé™¤ä¸å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    - ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢å¯¾ç­–
```

### ãƒ‡ãƒ¼ã‚¿åˆ†é¡ã«ã‚ˆã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥

```python
class DataClassification:
    def __init__(self):
        self.tiers = {
            'mission_critical': {
                'rpo': 15,  # 15åˆ†
                'rto': 30,  # 30åˆ†
                'backup_frequency': 'continuous',
                'retention_period': 2555,  # 7å¹´
                'geographic_distribution': 3,  # 3ã¤ã®åœ°åŸŸ
                'backup_method': 'synchronous_replication'
            },
            'business_critical': {
                'rpo': 60,  # 1æ™‚é–“
                'rto': 240,  # 4æ™‚é–“
                'backup_frequency': 'hourly',
                'retention_period': 1095,  # 3å¹´
                'geographic_distribution': 2,  # 2ã¤ã®åœ°åŸŸ
                'backup_method': 'asynchronous_replication'
            },
            'operational': {
                'rpo': 1440,  # 24æ™‚é–“
                'rto': 1440,  # 24æ™‚é–“
                'backup_frequency': 'daily',
                'retention_period': 365,  # 1å¹´
                'geographic_distribution': 1,  # 1ã¤ã®åœ°åŸŸ
                'backup_method': 'scheduled_snapshot'
            },
            'archival': {
                'rpo': 10080,  # 7æ—¥
                'rto': 10080,  # 7æ—¥
                'backup_frequency': 'weekly',
                'retention_period': 3650,  # 10å¹´
                'geographic_distribution': 1,
                'backup_method': 'cold_storage'
            }
        }
    
    def get_backup_strategy(self, data_type: str) -> dict:
        return self.tiers.get(data_type, self.tiers['operational'])
    
    def calculate_backup_cost(self, data_size_gb: int, data_type: str) -> dict:
        strategy = self.get_backup_strategy(data_type)
        
        # AWSæ–™é‡‘ã‚’ä¾‹ã¨ã—ãŸè¨ˆç®—
        costs = {
            'primary_storage': data_size_gb * 0.023,  # S3 Standard
            'backup_storage': data_size_gb * 0.0125,  # S3 IA
            'archive_storage': data_size_gb * 0.004,  # S3 Glacier
            'replication_cost': data_size_gb * 0.02,  # Cross-region replication
            'retrieval_cost': data_size_gb * 0.01 * (strategy['retention_period'] / 365)
        }
        
        return costs

# ä½¿ç”¨ä¾‹
classifier = DataClassification()
strategy = classifier.get_backup_strategy('mission_critical')
costs = classifier.calculate_backup_cost(1000, 'mission_critical')

print(f"Mission Critical Data Strategy: {strategy}")
print(f"Annual Backup Cost for 1TB: ${sum(costs.values()):.2f}")
```

## 8.3 ã‚¯ãƒ©ã‚¦ãƒ‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒ“ã‚¹ã®å®Ÿè£…

### AWS Backup ã®å®Ÿè£…

```python
import boto3
import json
from datetime import datetime, timedelta

class AWSBackupManager:
    def __init__(self, region='us-east-1'):
        self.backup_client = boto3.client('backup', region_name=region)
        self.iam_client = boto3.client('iam', region_name=region)
        
    def create_backup_vault(self, vault_name: str, kms_key_id: str = None):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒœãƒ«ãƒˆã®ä½œæˆ"""
        try:
            response = self.backup_client.create_backup_vault(
                BackupVaultName=vault_name,
                EncryptionKeyArn=kms_key_id
            )
            return response
        except Exception as e:
            print(f"Error creating backup vault: {e}")
            return None
    
    def create_backup_plan(self, plan_name: str, rules: list):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨ˆç”»ã®ä½œæˆ"""
        backup_plan = {
            'BackupPlanName': plan_name,
            'Rules': rules
        }
        
        try:
            response = self.backup_client.create_backup_plan(
                BackupPlan=backup_plan
            )
            return response
        except Exception as e:
            print(f"Error creating backup plan: {e}")
            return None
    
    def create_backup_selection(self, plan_id: str, selection_name: str, 
                              iam_role_arn: str, resources: list):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é¸æŠã®ä½œæˆ"""
        backup_selection = {
            'SelectionName': selection_name,
            'IamRoleArn': iam_role_arn,
            'Resources': resources
        }
        
        try:
            response = self.backup_client.create_backup_selection(
                BackupPlanId=plan_id,
                BackupSelection=backup_selection
            )
            return response
        except Exception as e:
            print(f"Error creating backup selection: {e}")
            return None

# ä½¿ç”¨ä¾‹
backup_manager = AWSBackupManager()

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒœãƒ«ãƒˆã®ä½œæˆ
backup_manager.create_backup_vault('production-backup-vault')

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ«ãƒ¼ãƒ«ã®å®šç¾©
daily_backup_rule = {
    'RuleName': 'DailyBackup',
    'TargetBackupVault': 'production-backup-vault',
    'ScheduleExpression': 'cron(0 2 ? * * *)',  # æ¯æ—¥åˆå‰2æ™‚
    'StartWindowMinutes': 60,
    'CompletionWindowMinutes': 120,
    'Lifecycle': {
        'DeleteAfterDays': 30,
        'MoveToColdStorageAfterDays': 7
    }
}

weekly_backup_rule = {
    'RuleName': 'WeeklyBackup',
    'TargetBackupVault': 'production-backup-vault',
    'ScheduleExpression': 'cron(0 3 ? * SUN *)',  # æ¯é€±æ—¥æ›œæ—¥åˆå‰3æ™‚
    'StartWindowMinutes': 60,
    'CompletionWindowMinutes': 240,
    'Lifecycle': {
        'DeleteAfterDays': 365,
        'MoveToColdStorageAfterDays': 30
    }
}

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨ˆç”»ã®ä½œæˆ
backup_plan_response = backup_manager.create_backup_plan(
    'production-backup-plan',
    [daily_backup_rule, weekly_backup_rule]
)
```

### Azure Backup ã®å®Ÿè£…

```python
from azure.mgmt.recoveryservices import RecoveryServicesClient
from azure.mgmt.recoveryservicesbackup import RecoveryServicesBackupClient
from azure.identity import DefaultAzureCredential

class AzureBackupManager:
    def __init__(self, subscription_id: str):
        self.credential = DefaultAzureCredential()
        self.recovery_client = RecoveryServicesClient(
            self.credential, subscription_id
        )
        self.backup_client = RecoveryServicesBackupClient(
            self.credential, subscription_id
        )
        
    def create_recovery_vault(self, resource_group: str, vault_name: str, 
                             location: str):
        """Recovery Servicesãƒœãƒ«ãƒˆã®ä½œæˆ"""
        vault_parameters = {
            'location': location,
            'sku': {
                'name': 'Standard'
            },
            'properties': {}
        }
        
        try:
            vault = self.recovery_client.vaults.create_or_update(
                resource_group, vault_name, vault_parameters
            )
            return vault
        except Exception as e:
            print(f"Error creating recovery vault: {e}")
            return None
    
    def create_backup_policy(self, vault_name: str, resource_group: str, 
                           policy_name: str, policy_config: dict):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒãƒªã‚·ãƒ¼ã®ä½œæˆ"""
        policy_parameters = {
            'properties': {
                'backup_management_type': 'AzureIaasVM',
                'schedule_policy': {
                    'schedule_policy_type': 'SimpleSchedulePolicy',
                    'schedule_run_frequency': policy_config['frequency'],
                    'schedule_run_times': policy_config['times'],
                    'schedule_run_days': policy_config.get('days', [])
                },
                'retention_policy': {
                    'retention_policy_type': 'LongTermRetentionPolicy',
                    'daily_schedule': {
                        'retention_duration': {
                            'count': policy_config['daily_retention'],
                            'duration_type': 'Days'
                        }
                    }
                }
            }
        }
        
        try:
            policy = self.backup_client.protection_policies.create_or_update(
                vault_name, resource_group, policy_name, policy_parameters
            )
            return policy
        except Exception as e:
            print(f"Error creating backup policy: {e}")
            return None

# ä½¿ç”¨ä¾‹
azure_backup = AzureBackupManager('your-subscription-id')

# Recovery Servicesãƒœãƒ«ãƒˆã®ä½œæˆ
vault = azure_backup.create_recovery_vault(
    'production-rg', 'production-vault', 'japaneast'
)

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒãƒªã‚·ãƒ¼ã®ä½œæˆ
policy_config = {
    'frequency': 'Daily',
    'times': ['02:00'],
    'daily_retention': 30
}

policy = azure_backup.create_backup_policy(
    'production-vault', 'production-rg', 'daily-backup-policy', policy_config
)
```

## 8.4 ç½å®³å¾©æ—§è¨ˆç”»ã®ç­–å®š

### ç½å®³å¾©æ—§æˆ¦ç•¥ã®é¸æŠ

```yaml
DRæˆ¦ç•¥ã®ç¨®é¡:
  1. Backup and Restore (å®‰ä¾¡):
     - RPO: æ™‚é–“ï½æ—¥
     - RTO: æ™‚é–“ï½æ—¥
     - ã‚³ã‚¹ãƒˆ: ä½
     - é©ç”¨: éã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ã‚¹ãƒ†ãƒ 
     
  2. Pilot Light (æœ€å°é™):
     - RPO: åˆ†ï½æ™‚é–“
     - RTO: æ•°æ™‚é–“
     - ã‚³ã‚¹ãƒˆ: ä¸­
     - é©ç”¨: é‡è¦ã ãŒçŸ­æ™‚é–“åœæ­¢è¨±å®¹
     
  3. Warm Standby (æº–å‚™çŠ¶æ…‹):
     - RPO: ç§’ï½åˆ†
     - RTO: åˆ†ï½æ™‚é–“
     - ã‚³ã‚¹ãƒˆ: é«˜
     - é©ç”¨: ãƒ“ã‚¸ãƒã‚¹ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«
     
  4. Multi-Site Active/Active (å¸¸æ™‚ç¨¼åƒ):
     - RPO: 0ï½ç§’
     - RTO: 0ï½åˆ†
     - ã‚³ã‚¹ãƒˆ: æœ€é«˜
     - é©ç”¨: ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«
```

### ç½å®³å¾©æ—§ãƒ†ã‚¹ãƒˆã®è‡ªå‹•åŒ–

```python
import boto3
import time
from typing import Dict, List

class DisasterRecoveryTester:
    def __init__(self):
        self.ec2 = boto3.client('ec2')
        self.rds = boto3.client('rds')
        self.s3 = boto3.client('s3')
        
    def test_backup_restore(self, resources: Dict) -> Dict:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©æ—§ãƒ†ã‚¹ãƒˆ"""
        test_results = {
            'start_time': time.time(),
            'tests': [],
            'success_count': 0,
            'failure_count': 0
        }
        
        for resource_type, resource_configs in resources.items():
            if resource_type == 'ec2':
                result = self._test_ec2_recovery(resource_configs)
            elif resource_type == 'rds':
                result = self._test_rds_recovery(resource_configs)
            elif resource_type == 's3':
                result = self._test_s3_recovery(resource_configs)
            else:
                result = {'status': 'skipped', 'reason': 'unknown resource type'}
            
            test_results['tests'].append({
                'resource_type': resource_type,
                'resource_id': resource_configs.get('id'),
                'result': result
            })
            
            if result['status'] == 'success':
                test_results['success_count'] += 1
            else:
                test_results['failure_count'] += 1
        
        test_results['end_time'] = time.time()
        test_results['duration'] = test_results['end_time'] - test_results['start_time']
        
        return test_results
    
    def _test_ec2_recovery(self, config: Dict) -> Dict:
        """EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å¾©æ—§ãƒ†ã‚¹ãƒˆ"""
        try:
            # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ã®AMIä½œæˆ
            snapshot_id = config['snapshot_id']
            ami_response = self.ec2.create_image(
                InstanceId=config['instance_id'],
                Name=f"dr-test-{int(time.time())}",
                NoReboot=True
            )
            
            # AMIã®æº–å‚™å®Œäº†ã‚’å¾…æ©Ÿ
            ami_id = ami_response['ImageId']
            waiter = self.ec2.get_waiter('image_available')
            waiter.wait(ImageIds=[ami_id])
            
            # ãƒ†ã‚¹ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®èµ·å‹•
            instance_response = self.ec2.run_instances(
                ImageId=ami_id,
                MinCount=1,
                MaxCount=1,
                InstanceType=config['instance_type'],
                KeyName=config.get('key_name'),
                SecurityGroupIds=config.get('security_groups', []),
                SubnetId=config.get('subnet_id'),
                TagSpecifications=[{
                    'ResourceType': 'instance',
                    'Tags': [{'Key': 'Name', 'Value': 'DR-Test-Instance'}]
                }]
            )
            
            instance_id = instance_response['Instances'][0]['InstanceId']
            
            # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®èµ·å‹•å®Œäº†ã‚’å¾…æ©Ÿ
            waiter = self.ec2.get_waiter('instance_running')
            waiter.wait(InstanceIds=[instance_id])
            
            # å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
            health_check = self._perform_health_check(instance_id)
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.ec2.terminate_instances(InstanceIds=[instance_id])
            
            return {
                'status': 'success',
                'instance_id': instance_id,
                'health_check': health_check,
                'message': 'EC2 recovery test completed successfully'
            }
            
        except Exception as e:
            return {
                'status': 'failure',
                'error': str(e),
                'message': 'EC2 recovery test failed'
            }
    
    def _test_rds_recovery(self, config: Dict) -> Dict:
        """RDSã®å¾©æ—§ãƒ†ã‚¹ãƒˆ"""
        try:
            # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ã®DBå¾©å…ƒ
            snapshot_id = config['snapshot_id']
            test_db_identifier = f"dr-test-{int(time.time())}"
            
            restore_response = self.rds.restore_db_instance_from_db_snapshot(
                DBInstanceIdentifier=test_db_identifier,
                DBSnapshotIdentifier=snapshot_id,
                DBInstanceClass=config['instance_class'],
                MultiAZ=False,  # ãƒ†ã‚¹ãƒˆç”¨ãªã®ã§Single-AZ
                PubliclyAccessible=False,
                AutoMinorVersionUpgrade=False,
                Tags=[{'Key': 'Purpose', 'Value': 'DR-Test'}]
            )
            
            # DBå¾©å…ƒå®Œäº†ã‚’å¾…æ©Ÿ
            waiter = self.rds.get_waiter('db_instance_available')
            waiter.wait(DBInstanceIdentifier=test_db_identifier)
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            connection_test = self._test_db_connection(test_db_identifier)
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.rds.delete_db_instance(
                DBInstanceIdentifier=test_db_identifier,
                SkipFinalSnapshot=True
            )
            
            return {
                'status': 'success',
                'db_identifier': test_db_identifier,
                'connection_test': connection_test,
                'message': 'RDS recovery test completed successfully'
            }
            
        except Exception as e:
            return {
                'status': 'failure',
                'error': str(e),
                'message': 'RDS recovery test failed'
            }
    
    def _test_s3_recovery(self, config: Dict) -> Dict:
        """S3ã®å¾©æ—§ãƒ†ã‚¹ãƒˆ"""
        try:
            source_bucket = config['source_bucket']
            test_bucket = config['test_bucket']
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒã‚±ãƒƒãƒˆã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å¾©å…ƒ
            paginator = self.s3.get_paginator('list_objects_v2')
            pages = paginator.paginate(Bucket=source_bucket)
            
            objects_restored = 0
            for page in pages:
                if 'Contents' in page:
                    for obj in page['Contents']:
                        copy_source = {'Bucket': source_bucket, 'Key': obj['Key']}
                        self.s3.copy_object(
                            CopySource=copy_source,
                            Bucket=test_bucket,
                            Key=obj['Key']
                        )
                        objects_restored += 1
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            integrity_check = self._verify_s3_integrity(source_bucket, test_bucket)
            
            return {
                'status': 'success',
                'objects_restored': objects_restored,
                'integrity_check': integrity_check,
                'message': 'S3 recovery test completed successfully'
            }
            
        except Exception as e:
            return {
                'status': 'failure',
                'error': str(e),
                'message': 'S3 recovery test failed'
            }
    
    def _perform_health_check(self, instance_id: str) -> Dict:
        """ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            response = self.ec2.describe_instance_status(InstanceIds=[instance_id])
            if response['InstanceStatuses']:
                status = response['InstanceStatuses'][0]
                return {
                    'instance_status': status['InstanceStatus']['Status'],
                    'system_status': status['SystemStatus']['Status'],
                    'healthy': status['InstanceStatus']['Status'] == 'ok'
                }
            return {'healthy': False, 'reason': 'No status information available'}
        except Exception as e:
            return {'healthy': False, 'error': str(e)}
    
    def _test_db_connection(self, db_identifier: str) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            response = self.rds.describe_db_instances(DBInstanceIdentifier=db_identifier)
            db_instance = response['DBInstances'][0]
            
            return {
                'status': db_instance['DBInstanceStatus'],
                'engine': db_instance['Engine'],
                'connectable': db_instance['DBInstanceStatus'] == 'available'
            }
        except Exception as e:
            return {'connectable': False, 'error': str(e)}
    
    def _verify_s3_integrity(self, source_bucket: str, test_bucket: str) -> Dict:
        """S3ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            source_objects = self._list_s3_objects(source_bucket)
            test_objects = self._list_s3_objects(test_bucket)
            
            return {
                'source_count': len(source_objects),
                'test_count': len(test_objects),
                'match': len(source_objects) == len(test_objects)
            }
        except Exception as e:
            return {'match': False, 'error': str(e)}
    
    def _list_s3_objects(self, bucket_name: str) -> List[str]:
        """S3ãƒã‚±ãƒƒãƒˆå†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ã‚’å–å¾—"""
        objects = []
        paginator = self.s3.get_paginator('list_objects_v2')
        pages = paginator.paginate(Bucket=bucket_name)
        
        for page in pages:
            if 'Contents' in page:
                for obj in page['Contents']:
                    objects.append(obj['Key'])
        
        return objects

# ä½¿ç”¨ä¾‹
dr_tester = DisasterRecoveryTester()

test_resources = {
    'ec2': {
        'instance_id': 'i-1234567890abcdef0',
        'snapshot_id': 'snap-1234567890abcdef0',
        'instance_type': 't3.micro',
        'key_name': 'my-key-pair',
        'security_groups': ['sg-1234567890abcdef0'],
        'subnet_id': 'subnet-1234567890abcdef0'
    },
    'rds': {
        'snapshot_id': 'rds:production-db-2023-07-18-06-00',
        'instance_class': 'db.t3.micro'
    },
    's3': {
        'source_bucket': 'production-backup-bucket',
        'test_bucket': 'dr-test-bucket'
    }
}

test_results = dr_tester.test_backup_restore(test_resources)
print(f"DR Test Results: {test_results}")
```

## 8.5 äº‹æ¥­ç¶™ç¶šè¨ˆç”»ï¼ˆBCPï¼‰ã®ç­–å®š

### åŒ…æ‹¬çš„ãªBCPæˆ¦ç•¥

```yaml
BCPæ§‹æˆè¦ç´ :
  1. äº‹æ¥­å½±éŸ¿åº¦åˆ†æ (BIA):
     - ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã®ç‰¹å®š
     - å¾©æ—§æ™‚é–“ç›®æ¨™ã®è¨­å®š
     - å¾©æ—§å„ªå…ˆåº¦ã®æ±ºå®š
     
  2. ãƒªã‚¹ã‚¯ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆ:
     - è„…å¨ã®è­˜åˆ¥ã¨åˆ†æ
     - è„†å¼±æ€§ã®è©•ä¾¡
     - å½±éŸ¿åº¦ã®ç®—å‡º
     
  3. ç¶™ç¶šæˆ¦ç•¥:
     - ä»£æ›¿æ‰‹æ®µã®ç¢ºä¿
     - ä»£æ›¿æ‹ ç‚¹ã®æº–å‚™
     - ä»£æ›¿äººå“¡ã®ç¢ºä¿
     
  4. å¯¾å¿œè¨ˆç”»:
     - åˆæœŸå¯¾å¿œæ‰‹é †
     - å¾©æ—§æ‰‹é †
     - é€šä¿¡è¨ˆç”»
     
  5. è¨“ç·´ã¨ç¶­æŒ:
     - å®šæœŸçš„ãªè¨“ç·´
     - è¨ˆç”»ã®æ›´æ–°
     - æœ‰åŠ¹æ€§ã®æ¤œè¨¼
```

### é€šä¿¡è¨ˆç”»ã®è‡ªå‹•åŒ–

```python
import boto3
import json
from datetime import datetime
from typing import List, Dict

class CommunicationManager:
    def __init__(self):
        self.sns = boto3.client('sns')
        self.ses = boto3.client('ses')
        self.slack_webhook = None  # Slack Webhook URL
        
    def send_disaster_notification(self, severity: str, message: str, 
                                 recipients: List[str]) -> Dict:
        """ç½å®³é€šçŸ¥ã®é€ä¿¡"""
        
        notification_channels = {
            'critical': ['sms', 'email', 'slack', 'phone'],
            'high': ['email', 'slack'],
            'medium': ['email'],
            'low': ['slack']
        }
        
        channels = notification_channels.get(severity, ['email'])
        results = {}
        
        for channel in channels:
            if channel == 'sms':
                results['sms'] = self._send_sms(message, recipients)
            elif channel == 'email':
                results['email'] = self._send_email(message, recipients)
            elif channel == 'slack':
                results['slack'] = self._send_slack(message)
            elif channel == 'phone':
                results['phone'] = self._initiate_phone_calls(message, recipients)
        
        return results
    
    def _send_sms(self, message: str, recipients: List[str]) -> Dict:
        """SMSé€šçŸ¥ã®é€ä¿¡"""
        results = {'success': [], 'failures': []}
        
        for recipient in recipients:
            try:
                response = self.sns.publish(
                    PhoneNumber=recipient,
                    Message=message,
                    Subject='Disaster Recovery Alert'
                )
                results['success'].append(recipient)
            except Exception as e:
                results['failures'].append({'recipient': recipient, 'error': str(e)})
        
        return results
    
    def _send_email(self, message: str, recipients: List[str]) -> Dict:
        """Emailé€šçŸ¥ã®é€ä¿¡"""
        results = {'success': [], 'failures': []}
        
        for recipient in recipients:
            try:
                response = self.ses.send_email(
                    Source='noreply@company.com',
                    Destination={'ToAddresses': [recipient]},
                    Message={
                        'Subject': {'Data': 'Disaster Recovery Alert'},
                        'Body': {'Text': {'Data': message}}
                    }
                )
                results['success'].append(recipient)
            except Exception as e:
                results['failures'].append({'recipient': recipient, 'error': str(e)})
        
        return results
    
    def _send_slack(self, message: str) -> Dict:
        """Slacké€šçŸ¥ã®é€ä¿¡"""
        if not self.slack_webhook:
            return {'status': 'skipped', 'reason': 'webhook not configured'}
        
        try:
            import requests
            payload = {
                'text': f"ğŸš¨ DISASTER RECOVERY ALERT ğŸš¨\n{message}",
                'channel': '#incident-response',
                'username': 'DR-Bot'
            }
            
            response = requests.post(self.slack_webhook, json=payload)
            return {'status': 'success', 'response': response.status_code}
        except Exception as e:
            return {'status': 'failure', 'error': str(e)}
    
    def _initiate_phone_calls(self, message: str, recipients: List[str]) -> Dict:
        """è‡ªå‹•éŸ³å£°é€šè©±ã®é–‹å§‹"""
        results = {'success': [], 'failures': []}
        
        # Amazon Connect ã¾ãŸã¯ä»–ã®VoIPã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
        # ã“ã®ä¾‹ã§ã¯ã€SNSã‚’ä½¿ç”¨ã—ãŸç°¡å˜ãªå®Ÿè£…
        
        for recipient in recipients:
            try:
                # éŸ³å£°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
                voice_message = f"This is an automated disaster recovery alert. {message}"
                
                # éŸ³å£°é€šè©±ã®é–‹å§‹ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Connect APIã‚’ä½¿ç”¨ï¼‰
                response = self.sns.publish(
                    PhoneNumber=recipient,
                    Message=voice_message,
                    MessageAttributes={
                        'AWS.SNS.SMS.SMSType': {'DataType': 'String', 'StringValue': 'Transactional'}
                    }
                )
                results['success'].append(recipient)
            except Exception as e:
                results['failures'].append({'recipient': recipient, 'error': str(e)})
        
        return results

# ä½¿ç”¨ä¾‹
comm_manager = CommunicationManager()

# ç½å®³é€šçŸ¥ã®é€ä¿¡
notification_result = comm_manager.send_disaster_notification(
    severity='critical',
    message='Primary data center is down. Initiating DR procedures.',
    recipients=['+1234567890', 'admin@company.com']
)
```

## 8.6 ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢å¯¾ç­–

### ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å®Ÿè£…

```python
import boto3
import json
from datetime import datetime, timedelta

class ImmutableBackupManager:
    def __init__(self):
        self.s3 = boto3.client('s3')
        self.iam = boto3.client('iam')
        
    def create_immutable_backup_bucket(self, bucket_name: str, 
                                     retention_days: int = 2555) -> Dict:
        """ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨ã®S3ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆ"""
        try:
            # ãƒã‚±ãƒƒãƒˆã®ä½œæˆ
            self.s3.create_bucket(
                Bucket=bucket_name,
                CreateBucketConfiguration={'LocationConstraint': 'ap-northeast-1'}
            )
            
            # ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã®æœ‰åŠ¹åŒ–
            self.s3.put_bucket_versioning(
                Bucket=bucket_name,
                VersioningConfiguration={'Status': 'Enabled'}
            )
            
            # Object Lockã®è¨­å®š
            self.s3.put_object_lock_configuration(
                Bucket=bucket_name,
                ObjectLockConfiguration={
                    'ObjectLockEnabled': 'Enabled',
                    'Rule': {
                        'DefaultRetention': {
                            'Mode': 'GOVERNANCE',
                            'Days': retention_days
                        }
                    }
                }
            )
            
            # ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã®ãƒ–ãƒ­ãƒƒã‚¯
            self.s3.put_public_access_block(
                Bucket=bucket_name,
                PublicAccessBlockConfiguration={
                    'BlockPublicAcls': True,
                    'IgnorePublicAcls': True,
                    'BlockPublicPolicy': True,
                    'RestrictPublicBuckets': True
                }
            )
            
            # ãƒã‚±ãƒƒãƒˆãƒãƒªã‚·ãƒ¼ã®è¨­å®š
            bucket_policy = {
                "Version": "2012-10-17",
                "Statement": [
                    {
                        "Sid": "DenyDeleteObject",
                        "Effect": "Deny",
                        "Principal": "*",
                        "Action": [
                            "s3:DeleteObject",
                            "s3:DeleteObjectVersion"
                        ],
                        "Resource": f"arn:aws:s3:::{bucket_name}/*",
                        "Condition": {
                            "StringNotEquals": {
                                "aws:PrincipalServiceName": "backup.amazonaws.com"
                            }
                        }
                    }
                ]
            }
            
            self.s3.put_bucket_policy(
                Bucket=bucket_name,
                Policy=json.dumps(bucket_policy)
            )
            
            return {
                'status': 'success',
                'bucket_name': bucket_name,
                'retention_days': retention_days,
                'message': 'Immutable backup bucket created successfully'
            }
            
        except Exception as e:
            return {
                'status': 'failure',
                'error': str(e),
                'message': 'Failed to create immutable backup bucket'
            }
    
    def create_backup_with_legal_hold(self, bucket_name: str, 
                                    source_data: str, key: str) -> Dict:
        """Legal Holdã‚’è¨­å®šã—ãŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ"""
        try:
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            self.s3.put_object(
                Bucket=bucket_name,
                Key=key,
                Body=source_data,
                ObjectLockMode='GOVERNANCE',
                ObjectLockRetainUntilDate=datetime.now() + timedelta(days=365),
                ObjectLockLegalHoldStatus='ON'
            )
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
            self.s3.put_object_tagging(
                Bucket=bucket_name,
                Key=key,
                Tagging={
                    'TagSet': [
                        {'Key': 'BackupType', 'Value': 'Immutable'},
                        {'Key': 'CreatedDate', 'Value': datetime.now().isoformat()},
                        {'Key': 'LegalHold', 'Value': 'Active'}
                    ]
                }
            )
            
            return {
                'status': 'success',
                'bucket_name': bucket_name,
                'key': key,
                'message': 'Backup created with legal hold'
            }
            
        except Exception as e:
            return {
                'status': 'failure',
                'error': str(e),
                'message': 'Failed to create backup with legal hold'
            }
    
    def verify_backup_integrity(self, bucket_name: str, key: str) -> Dict:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
            response = self.s3.head_object(Bucket=bucket_name, Key=key)
            
            # Object Lockè¨­å®šã®ç¢ºèª
            lock_response = self.s3.get_object_legal_hold(Bucket=bucket_name, Key=key)
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            integrity_check = {
                'object_exists': True,
                'size': response['ContentLength'],
                'last_modified': response['LastModified'],
                'etag': response['ETag'],
                'legal_hold': lock_response['LegalHold']['Status'],
                'retention_mode': response.get('ObjectLockMode'),
                'retention_until': response.get('ObjectLockRetainUntilDate')
            }
            
            return {
                'status': 'success',
                'integrity_check': integrity_check,
                'message': 'Backup integrity verified'
            }
            
        except Exception as e:
            return {
                'status': 'failure',
                'error': str(e),
                'message': 'Failed to verify backup integrity'
            }

# ä½¿ç”¨ä¾‹
immutable_backup = ImmutableBackupManager()

# ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒã‚±ãƒƒãƒˆã®ä½œæˆ
bucket_result = immutable_backup.create_immutable_backup_bucket(
    'production-immutable-backups',
    retention_days=2555  # 7å¹´ä¿æŒ
)

# Legal Holdã‚’è¨­å®šã—ãŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ
backup_result = immutable_backup.create_backup_with_legal_hold(
    'production-immutable-backups',
    'important_data_content',
    'database_backup_2023_07_18.sql'
)

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
integrity_result = immutable_backup.verify_backup_integrity(
    'production-immutable-backups',
    'database_backup_2023_07_18.sql'
)
```

## ã¾ã¨ã‚ï¼šæŒç¶šå¯èƒ½ãªç½å®³å¾©æ—§æˆ¦ç•¥

åŠ¹æœçš„ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ç½å®³å¾©æ—§æˆ¦ç•¥ã®å®Ÿè£…ã«ã¯ã€ä»¥ä¸‹ã®è¦ç´ ãŒé‡è¦ã§ã™ï¼š

### é‡è¦ãªå®Ÿè£…ãƒã‚¤ãƒ³ãƒˆ

1. **æ®µéšçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**
   - åŸºæœ¬çš„ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰é–‹å§‹
   - å¾ã€…ã«DRæ©Ÿèƒ½ã‚’å¼·åŒ–
   - å®šæœŸçš„ãªãƒ†ã‚¹ãƒˆã¨æ”¹å–„

2. **ã‚³ã‚¹ãƒˆã¨åŠ¹æœã®ãƒãƒ©ãƒ³ã‚¹**
   - ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã«å¿œã˜ãŸæˆ¦ç•¥é¸æŠ
   - é©åˆ‡ãªRPO/RTOã®è¨­å®š
   - ã‚¯ãƒ©ã‚¦ãƒ‰ã®çµŒæ¸ˆæ€§ã‚’æ´»ç”¨

3. **è‡ªå‹•åŒ–ã®æ¨é€²**
   - æ‰‹å‹•ãƒ—ãƒ­ã‚»ã‚¹ã®æœ€å°åŒ–
   - ç¶™ç¶šçš„ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
   - è¿…é€Ÿãªå¾©æ—§å¯¾å¿œ

4. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ç¢ºä¿**
   - ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
   - æš—å·åŒ–ã®å®Ÿè£…
   - ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã®å¼·åŒ–

5. **çµ„ç¹”çš„ãªæº–å‚™**
   - æ˜ç¢ºãªå½¹å‰²åˆ†æ‹…
   - å®šæœŸçš„ãªè¨“ç·´
   - é€šä¿¡è¨ˆç”»ã®æ•´å‚™

ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã®ç‰¹æ€§ã‚’æ´»ã‹ã—ãŸç½å®³å¾©æ—§æˆ¦ç•¥ã«ã‚ˆã‚Šã€å¾“æ¥ã‚ˆã‚Šã‚‚ä½ã‚³ã‚¹ãƒˆã§é«˜ã„å¾©æ—§èƒ½åŠ›ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚é‡è¦ãªã®ã¯ã€çµ„ç¹”ã®ãƒªã‚¹ã‚¯è¨±å®¹åº¦ã¨ãƒ“ã‚¸ãƒã‚¹è¦ä»¶ã«å¿œã˜ãŸé©åˆ‡ãªæˆ¦ç•¥ã‚’é¸æŠã—ã€ç¶™ç¶šçš„ã«æ”¹å–„ã™ã‚‹ã“ã¨ã§ã™ã€‚

---

[ç¬¬09ç« ](../chapter-chapter09/index.md)ã¸é€²ã‚€